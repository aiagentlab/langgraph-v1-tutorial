{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë„êµ¬(Tools)\n",
    "\n",
    "ë§ì€ AI ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ìì—°ì–´ë¥¼ í†µí•´ ì‚¬ìš©ìì™€ ìƒí˜¸ ì‘ìš©í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì¼ë¶€ ì‚¬ìš© ì‚¬ë¡€ì—ì„œëŠ” ëª¨ë¸ì´ êµ¬ì¡°í™”ëœ ì…ë ¥ì„ ì‚¬ìš©í•˜ì—¬ API, ë°ì´í„°ë² ì´ìŠ¤ ë˜ëŠ” íŒŒì¼ ì‹œìŠ¤í…œê³¼ ê°™ì€ ì™¸ë¶€ ì‹œìŠ¤í…œê³¼ ì§ì ‘ ì¸í„°í˜ì´ìŠ¤í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë„êµ¬ëŠ” ì—ì´ì „íŠ¸ê°€ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ í˜¸ì¶œí•˜ëŠ” êµ¬ì„± ìš”ì†Œì…ë‹ˆë‹¤. \n",
    "\n",
    "ì˜ ì •ì˜ëœ ì…ë ¥ê³¼ ì¶œë ¥ì„ í†µí•´ ëª¨ë¸ì´ ì„¸ìƒê³¼ ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆë„ë¡ í•˜ì—¬ ëª¨ë¸ ê¸°ëŠ¥ì„ í™•ì¥í•©ë‹ˆë‹¤. \n",
    "\n",
    "ë„êµ¬ëŠ” í˜¸ì¶œ ê°€ëŠ¥í•œ í•¨ìˆ˜ì™€ ì…ë ¥ ìŠ¤í‚¤ë§ˆë¥¼ ìº¡ìŠí™”í•©ë‹ˆë‹¤. ì´ë“¤ì€ í˜¸í™˜ ê°€ëŠ¥í•œ ì±„íŒ… ëª¨ë¸ì— ì „ë‹¬ë  ìˆ˜ ìˆìœ¼ë©°, ëª¨ë¸ì´ ë„êµ¬ë¥¼ í˜¸ì¶œí• ì§€ ì—¬ë¶€ì™€ ì–´ë–¤ ì¸ìˆ˜ë¡œ í˜¸ì¶œí• ì§€ë¥¼ ê²°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì‚¬ì „ ì¤€ë¹„\n",
    "\n",
    "í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "LangChain-V1-Tutorial\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv(override=True)\n",
    "# ì¶”ì ì„ ìœ„í•œ í”„ë¡œì íŠ¸ ì´ë¦„ ì„¤ì •\n",
    "logging.langsmith(\"LangChain-V1-Tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë„êµ¬ ìƒì„±\n",
    "\n",
    "### ê¸°ë³¸ ë„êµ¬ ì •ì˜\n",
    "\n",
    "ë„êµ¬ë¥¼ ìƒì„±í•˜ëŠ” ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì€ `@tool` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. \n",
    "\n",
    "ê¸°ë³¸ì ìœ¼ë¡œ í•¨ìˆ˜ì˜ docstring ì´ ëª¨ë¸ì´ ë„êµ¬ë¥¼ ì–¸ì œ ì‚¬ìš©í• ì§€ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ë„êµ¬ì˜ ì„¤ëª…ì´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì¦‰, ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "1. `@tool` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë„êµ¬ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "2. ë„êµ¬ì˜ ì´ë¦„ì€ í•¨ìˆ˜ ì´ë¦„ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "3. ë„êµ¬ì˜ ì„¤ëª…ì€ í•¨ìˆ˜ì˜ docstring ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "4. ë„êµ¬ì˜ ì…ë ¥ ìŠ¤í‚¤ë§ˆëŠ” í•¨ìˆ˜ì˜ ë§¤ê°œë³€ìˆ˜ì™€ íƒ€ì… íŒíŠ¸ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool name: search_database\n",
      "Tool description: Search the customer database for records matching the query.\n",
      "\n",
      "    Args:\n",
      "        query: Search terms to look for\n",
      "        limit: Maximum number of results to return\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_database(query: str, limit: int = 10) -> str:\n",
    "    \"\"\"Search the customer database for records matching the query.\n",
    "\n",
    "    Args:\n",
    "        query: Search terms to look for\n",
    "        limit: Maximum number of results to return\n",
    "    \"\"\"\n",
    "    return f\"Found {limit} results for '{query}'\"\n",
    "\n",
    "\n",
    "# ë„êµ¬ ì •ë³´ í™•ì¸\n",
    "print(f\"Tool name: {search_database.name}\")\n",
    "print(f\"Tool description: {search_database.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "íƒ€ì… íŒíŠ¸ëŠ” ë„êµ¬ì˜ ì…ë ¥ ìŠ¤í‚¤ë§ˆë¥¼ ì •ì˜í•˜ë¯€ë¡œ í•„ìˆ˜ì…ë‹ˆë‹¤. \n",
    "\n",
    "docstringì€ ëª¨ë¸ì´ ë„êµ¬ì˜ ëª©ì ì„ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë˜ë„ë¡ ì •ë³´ê°€ í’ë¶€í•˜ê³  ê°„ê²°í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë„êµ¬ ì†ì„± ì»¤ìŠ¤í„°ë§ˆì´ì§•\n",
    "\n",
    "#### ì»¤ìŠ¤í…€ ë„êµ¬ ì´ë¦„(Tool Name)\n",
    "\n",
    "ê¸°ë³¸ì ìœ¼ë¡œ ë„êµ¬ ì´ë¦„ì€ í•¨ìˆ˜ ì´ë¦„ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤. ë” ì„¤ëª…ì ì¸ ì´ë¦„ì´ í•„ìš”í•œ ê²½ìš° ì´ë¥¼ ì•„ë˜ì™€ ê°™ì´ ì¬ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "`@tool(\"ì»¤ìŠ¤í…€ ì´ë¦„\")` ì„ ì‚¬ìš©í•˜ì—¬ ë„êµ¬ ì´ë¦„ì„ ì¬ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool name: web_search\n"
     ]
    }
   ],
   "source": [
    "@tool(\"web_search\")  # ì»¤ìŠ¤í…€ ì´ë¦„\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search the web for information.\"\"\"\n",
    "    return f\"Results for: {query}\"\n",
    "\n",
    "\n",
    "# ë„êµ¬ ì´ë¦„ í™•ì¸\n",
    "print(f\"Tool name: {search.name}\")  # web_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ì»¤ìŠ¤í…€ ë„êµ¬ ì„¤ëª…(Tool Description)\n",
    "\n",
    "ë” ëª…í™•í•œ ëª¨ë¸ ê°€ì´ë“œë¥¼ ìœ„í•´ ìë™ ìƒì„±ëœ ë„êµ¬ ì„¤ëª…ì„ ì¬ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "`@tool(description=\"ì»¤ìŠ¤í…€ ì„¤ëª…\")` ì„ ì‚¬ìš©í•˜ì—¬ ë„êµ¬ì˜ ì„¤ëª…ì„ ì¬ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool description: Performs arithmetic calculations. Use this for any math problems.\n"
     ]
    }
   ],
   "source": [
    "@tool(\n",
    "    \"calculator\",\n",
    "    description=\"Performs arithmetic calculations. Use this for any math problems.\",\n",
    ")\n",
    "def calc(expression: str) -> str:\n",
    "    \"\"\"Evaluate mathematical expressions.\"\"\"\n",
    "    return str(eval(expression))\n",
    "\n",
    "\n",
    "# ë„êµ¬ ì„¤ëª… í™•ì¸\n",
    "print(f\"Tool description: {calc.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pydantic ëª¨ë¸ë¡œ ë„êµ¬ë¥¼ ìœ„í•œ ìŠ¤í‚¤ë§ˆ ì •ì˜\n",
    "\n",
    "pydantic ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ëª…í™•í•œ ì…ë ¥ ìŠ¤í‚¤ë§ˆë¥¼ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "`@tool(args_schema=pydantic_model)` ì„ ì‚¬ìš©í•˜ì—¬ ë„êµ¬ì˜ ì…ë ¥ ìŠ¤í‚¤ë§ˆë¥¼ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "class WeatherInput(BaseModel):\n",
    "    \"\"\"Input for weather queries.\"\"\"\n",
    "\n",
    "    location: str = Field(description=\"City name or coordinates\")\n",
    "    units: Literal[\"celsius\", \"fahrenheit\"] = Field(\n",
    "        default=\"celsius\", description=\"Temperature unit preference\"\n",
    "    )\n",
    "    include_forecast: bool = Field(default=False, description=\"Include 5-day forecast\")\n",
    "\n",
    "\n",
    "@tool(args_schema=WeatherInput)\n",
    "def get_weather(\n",
    "    location: str, units: str = \"celsius\", include_forecast: bool = False\n",
    ") -> str:\n",
    "    \"\"\"Get current weather and optional forecast.\"\"\"\n",
    "    temp = 22 if units == \"celsius\" else 72\n",
    "    result = f\"í˜„ì¬ {location} ì§€ì—­ì˜ ë‚ ì”¨ëŠ” {temp} {units[0].upper()} ë„\"\n",
    "    if include_forecast:\n",
    "        result += \"\\në‹¤ìŒ 5ì¼ ë‚ ì”¨: ë§‘ìŒ\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ Seoul ì§€ì—­ì˜ ë‚ ì”¨ëŠ” 22 C ë„\n",
      "ë‹¤ìŒ 5ì¼ ë‚ ì”¨: ë§‘ìŒ\n"
     ]
    }
   ],
   "source": [
    "# ë„êµ¬ í…ŒìŠ¤íŠ¸\n",
    "print(\n",
    "    get_weather.invoke(\n",
    "        {\"location\": \"Seoul\", \"units\": \"celsius\", \"include_forecast\": True}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì•„ë˜ëŠ” ê³ ì˜ë¡œ `units` ë¥¼ `celsiuss` ë¡œ ì„¤ì •í•˜ì—¬ ì˜¤ë¥˜ë¥¼ ë°œìƒì‹œì¼œ ë³´ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ì˜ ê²½ìš° ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì´ìœ ëŠ” ì…ë ¥ ìŠ¤í‚¤ë§ˆì—ì„œ `Literal[\"celsius\", \"fahrenheit\"]` íƒ€ì…ì„ ì‚¬ìš©í•˜ì˜€ìœ¼ë‚˜, ì‹¤ì œ ì…ë ¥ê°’ìœ¼ë¡œ `celsiuss` ë¥¼ ì…ë ¥í–ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for WeatherInput\nunits\n  Input should be 'celsius' or 'fahrenheit' [type=literal_error, input_value='celsiuss', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/literal_error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ë„êµ¬ í…ŒìŠ¤íŠ¸\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mget_weather\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlocation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSeoul\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43munits\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcelsiuss\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_forecast\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/github/00-LangGraph-Tutorial/langgraph-v1-tutorial/.venv/lib/python3.11/site-packages/langchain_core/tools/base.py:591\u001b[39m, in \u001b[36mBaseTool.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    583\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    584\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    585\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    588\u001b[39m     **kwargs: Any,\n\u001b[32m    589\u001b[39m ) -> Any:\n\u001b[32m    590\u001b[39m     tool_input, kwargs = _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m591\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/github/00-LangGraph-Tutorial/langgraph-v1-tutorial/.venv/lib/python3.11/site-packages/langchain_core/tools/base.py:856\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    854\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    855\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m856\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    857\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    858\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/github/00-LangGraph-Tutorial/langgraph-v1-tutorial/.venv/lib/python3.11/site-packages/langchain_core/tools/base.py:818\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    816\u001b[39m child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m    817\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m818\u001b[39m     tool_args, tool_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_args_and_kwargs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    819\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\n\u001b[32m    820\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m signature(\u001b[38;5;28mself\u001b[39m._run).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    822\u001b[39m         tool_kwargs |= {\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m: run_manager}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/github/00-LangGraph-Tutorial/langgraph-v1-tutorial/.venv/lib/python3.11/site-packages/langchain_core/tools/base.py:733\u001b[39m, in \u001b[36mBaseTool._to_args_and_kwargs\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    725\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    726\u001b[39m     \u001b[38;5;28mself\u001b[39m.args_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    727\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.args_schema, \u001b[38;5;28mtype\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m    730\u001b[39m ):\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# StructuredTool with no args\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (), {}\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m tool_input = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;66;03m# For backwards compatibility, if run_input is a string,\u001b[39;00m\n\u001b[32m    735\u001b[39m \u001b[38;5;66;03m# pass as a positional argument.\u001b[39;00m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool_input, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/github/00-LangGraph-Tutorial/langgraph-v1-tutorial/.venv/lib/python3.11/site-packages/langchain_core/tools/base.py:657\u001b[39m, in \u001b[36mBaseTool._parse_input\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    655\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    656\u001b[39m             tool_input[k] = tool_call_id\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m     result = \u001b[43minput_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m     result_dict = result.model_dump()\n\u001b[32m    659\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(input_args, BaseModelV1):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/github/00-LangGraph-Tutorial/langgraph-v1-tutorial/.venv/lib/python3.11/site-packages/pydantic/main.py:716\u001b[39m, in \u001b[36mBaseModel.model_validate\u001b[39m\u001b[34m(cls, obj, strict, extra, from_attributes, context, by_alias, by_name)\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m by_alias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    711\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    712\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAt least one of `by_alias` or `by_name` must be set to True.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    713\u001b[39m         code=\u001b[33m'\u001b[39m\u001b[33mvalidate-by-alias-and-name-false\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    714\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m    \u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for WeatherInput\nunits\n  Input should be 'celsius' or 'fahrenheit' [type=literal_error, input_value='celsiuss', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/literal_error"
     ]
    }
   ],
   "source": [
    "# ë„êµ¬ í…ŒìŠ¤íŠ¸\n",
    "print(\n",
    "    get_weather.invoke(\n",
    "        {\"location\": \"Seoul\", \"units\": \"celsiuss\", \"include_forecast\": True}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì»¨í…ìŠ¤íŠ¸ ì ‘ê·¼\n",
    "\n",
    "ë„êµ¬ëŠ” ì—ì´ì „íŠ¸ ìƒíƒœ, ëŸ°íƒ€ì„ ì»¨í…ìŠ¤íŠ¸ ë° ì¥ê¸° ë©”ëª¨ë¦¬ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆì„ ë•Œ ê°€ì¥ ê°•ë ¥í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë„êµ¬ëŠ” ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ê²°ì •ì„ ë‚´ë¦¬ê³ , ì‘ë‹µì„ ê°œì¸í™”í•˜ë©°, ëŒ€í™” ì „ë°˜ì— ê±¸ì³ ì •ë³´ë¥¼ ìœ ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë„êµ¬ëŠ” `ToolRuntime` ë§¤ê°œë³€ìˆ˜ë¥¼ í†µí•´ ëŸ°íƒ€ì„ ì •ë³´ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìœ¼ë©°, ë‹¤ìŒì˜ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "- **State** - ì‹¤í–‰ì„ í†µí•´ íë¥´ëŠ” ë³€ê²½ ê°€ëŠ¥í•œ ë°ì´í„° (ë©”ì‹œì§€, ì¹´ìš´í„°, ì»¤ìŠ¤í…€ í•„ë“œ)\n",
    "- **Context** - ì‚¬ìš©ì ID, ì„¸ì…˜ ì„¸ë¶€ ì •ë³´ ë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ë³„ êµ¬ì„±ê³¼ ê°™ì€ ë¶ˆë³€ êµ¬ì„±\n",
    "- **Store** - ëŒ€í™” ì „ë°˜ì— ê±¸ì¹œ ì˜êµ¬ ì¥ê¸° ë©”ëª¨ë¦¬\n",
    "- **Stream Writer** - ë„êµ¬ê°€ ì‹¤í–‰ë  ë•Œ ì»¤ìŠ¤í…€ ì—…ë°ì´íŠ¸ ìŠ¤íŠ¸ë¦¬ë°\n",
    "- **Config** - ì‹¤í–‰ì„ ìœ„í•œ RunnableConfig\n",
    "- **Tool Call ID** - í˜„ì¬ ë„êµ¬ í˜¸ì¶œì˜ ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToolRuntime\n",
    "\n",
    "`ToolRuntime`ì„ ì‚¬ìš©í•˜ì—¬ ë‹¨ì¼ ë§¤ê°œë³€ìˆ˜ë¡œ ëª¨ë“  ëŸ°íƒ€ì„ ì •ë³´ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "\n",
    "ë„êµ¬ ì‹œê·¸ë‹ˆì²˜ì— `runtime: ToolRuntime`ì„ ì¶”ê°€í•˜ê¸°ë§Œ í•˜ë©´ LLMì— ë…¸ì¶œë˜ì§€ ì•Šê³  ìë™ìœ¼ë¡œ ì£¼ì…ë©ë‹ˆë‹¤.\n",
    "\n",
    "ë„êµ¬ëŠ” `ToolRuntime`ì„ ì‚¬ìš©í•˜ì—¬ í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_user_preference (call_P2lUJ30JDa0ognrMVgsHabE4)\n",
      " Call ID: call_P2lUJ30JDa0ognrMVgsHabE4\n",
      "  Args:\n",
      "    preference_name: food\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_user_preference\n",
      "\n",
      "pizza\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teddy/Dev/github/00-LangGraph-Tutorial/langgraph-v1-tutorial/.venv/lib/python3.11/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='context', input_value=CustomContext(user_preferences={'food': 'pizza'}), input_type=CustomContext])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ë‹¹ì‹ ì´ ì¢‹ì•„í•˜ëŠ” ìŒì‹ì€ í”¼ìì…ë‹ˆë‹¤. ë‹¤ë¥¸ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal, Optional, Dict, Any, List, Annotated, TypedDict\n",
    "from pydantic import BaseModel\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_teddynote.messages import stream_graph, invoke_graph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "\n",
    "# í˜„ì¬ ëŒ€í™” ìƒíƒœ ì ‘ê·¼\n",
    "@tool\n",
    "def summarize_conversation(runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Summarize the conversation so far.\"\"\"\n",
    "    # state ì—ì„œ ë©”ì‹œì§€ ì ‘ê·¼\n",
    "    messages = runtime.state.get(\"messages\", [])\n",
    "    human_msgs = sum(1 for m in messages if m.__class__.__name__ == \"HumanMessage\")\n",
    "    ai_msgs = sum(1 for m in messages if m.__class__.__name__ == \"AIMessage\")\n",
    "    tool_msgs = sum(1 for m in messages if m.__class__.__name__ == \"ToolMessage\")\n",
    "    return f\"Conversation has {human_msgs} user messages, {ai_msgs} AI responses, and {tool_msgs} tool results\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_user_preference(\n",
    "    preference_name: Literal[\"food\", \"coding\", \"sports\"],\n",
    "    runtime: ToolRuntime,  # ToolRuntime ë§¤ê°œë³€ìˆ˜ëŠ” ëª¨ë¸ì— ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤ (ìë™ ì£¼ì…)\n",
    ") -> str:\n",
    "    \"\"\"Get a user preference value.\"\"\"\n",
    "\n",
    "    # contextëŠ” stateì— ì €ì¥í•˜ì§€ ì•Šê³  ë³„ë„ì˜ context ê°ì²´ë¡œ injectë¨\n",
    "    preferences = {}\n",
    "    if getattr(runtime, \"context\", None) is not None:\n",
    "        # context dict ë‚´ user_preferences\n",
    "        preferences = runtime.context.user_preferences or {}\n",
    "    return preferences.get(preference_name, \"Have no information\")\n",
    "\n",
    "\n",
    "class CustomContext(BaseModel):\n",
    "    user_preferences: Optional[Dict[str, Any]] = None\n",
    "\n",
    "\n",
    "class CustomState(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "    user_preferences: Optional[Dict[str, Any]] = None\n",
    "\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ìƒì„±\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[summarize_conversation, get_user_preference],\n",
    "    system_prompt=\"You are a helpful assistant.\",\n",
    "    # checkpointer=InMemorySaver(),\n",
    "    context_schema=CustomContext,\n",
    "    # state_schema=CustomState,\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"ë‚´ê°€ ì¢‹ì•„í•˜ëŠ” ìŒì‹ ì•Œë ¤ì¤˜\"}]}\n",
    "\n",
    "invoke_graph(\n",
    "    agent,\n",
    "    inputs=inputs,\n",
    "    config=config,\n",
    "    context=CustomContext(user_preferences={\"food\": \"pizza\"}),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ìƒíƒœ ì—…ë°ì´íŠ¸\n",
    "\n",
    "`Command`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ì˜ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ê±°ë‚˜ ê·¸ë˜í”„ì˜ ì‹¤í–‰ íë¦„ì„ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langgraph.types import Command\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain.messages import AnyMessage, RemoveMessage, ToolMessage\n",
    "from langchain_teddynote.messages import invoke_graph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from typing import Annotated, List, Optional, Dict, Any\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class CustomContext(BaseModel):\n",
    "    user_preferences: Optional[Dict[str, Any]] = None\n",
    "\n",
    "\n",
    "class CustomState(BaseModel):\n",
    "    user_name: str = Field(default=\"\", description=\"The user's name\")\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "# User Name ì—…ë°ì´íŠ¸ ë„êµ¬\n",
    "@tool\n",
    "def update_user_name(new_name: str, runtime: ToolRuntime) -> Command:\n",
    "    \"\"\"Update the user's name.\"\"\"\n",
    "    return Command(\n",
    "        update={\n",
    "            \"user_name\": new_name,  # user_name ìƒíƒœì— ì—…ë°ì´íŠ¸\n",
    "            \"messages\": [\n",
    "                ToolMessage(\n",
    "                    content=f\"Successfully updated user name to {new_name}\",\n",
    "                    tool_call_id=runtime.tool_call_id,  # runtime ì—ì„œ ì–»ì–´ì˜¨ tool_call_id ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ì—…ë°ì´íŠ¸\n",
    "                )\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "@tool\n",
    "def clear_messages(runtime: ToolRuntime) -> Command:\n",
    "    \"\"\"Clear all messages from the conversation history except the one whose tool_call_id matches the id we don't want to delete.\"\"\"\n",
    "    from langchain.messages import AIMessage\n",
    "\n",
    "    messages = runtime.state.get(\"messages\", [])\n",
    "\n",
    "    to_remove_messages = []\n",
    "    tool_call_id = runtime.tool_call_id\n",
    "\n",
    "    for m in messages:\n",
    "        if isinstance(m, AIMessage) and getattr(m, \"tool_calls\", None):\n",
    "            # Tool Call ID ê°€ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ì‚­ì œ. Tool Call ID ê°€ ì¼ì¹˜í•˜ë©´ ìœ ì§€.\n",
    "            if not any(call.get(\"id\") == tool_call_id for call in m.tool_calls):\n",
    "                to_remove_messages.append(m)\n",
    "        else:\n",
    "            to_remove_messages.append(m)\n",
    "\n",
    "    removals = [RemoveMessage(id=m.id) for m in to_remove_messages]\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": removals\n",
    "            + [\n",
    "                ToolMessage(\n",
    "                    content=f\"Successfully cleared all previous messages. Total of {len(removals)} deleted messages.\",\n",
    "                    tool_call_id=runtime.tool_call_id,\n",
    "                )\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ìƒì„±\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[update_user_name, clear_messages],\n",
    "    system_prompt=\"You are a helpful assistant.\",\n",
    "    state_schema=CustomState,\n",
    "    context_schema=CustomContext,  # í´ë˜ìŠ¤ ìì²´ë¥¼ ì „ë‹¬ (ì¸ìŠ¤í„´ìŠ¤ê°€ ì•„ë‹˜)\n",
    "    checkpointer=InMemorySaver(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  update_user_name (call_8IpiHsQgS9fn0boyu48tEYce)\n",
      " Call ID: call_8IpiHsQgS9fn0boyu48tEYce\n",
      "  Args:\n",
      "    new_name: í…Œë””\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32muser_name\u001b[0m:\n",
      "í…Œë””\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_user_name\n",
      "\n",
      "Successfully updated user name to í…Œë””\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ì•ˆë…•í•˜ì„¸ìš”, í…Œë””ë‹˜! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ì—ì´ì „íŠ¸ ì‹¤í–‰\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "invoke_graph(\n",
    "    agent,\n",
    "    inputs={\"messages\": [{\"role\": \"user\", \"content\": \"ë‚´ ì´ë¦„ì€ í…Œë””ì•¼\"}]},\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  update_user_name (call_hxxyUlNbwu4vUWn16886zUaU)\n",
      " Call ID: call_hxxyUlNbwu4vUWn16886zUaU\n",
      "  Args:\n",
      "    new_name: ì…œë¦¬\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32muser_name\u001b[0m:\n",
      "ì…œë¦¬\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_user_name\n",
      "\n",
      "Successfully updated user name to ì…œë¦¬\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ì´ë¦„ì„ ì…œë¦¬ë¡œ ë³€ê²½í–ˆì–´ìš”. ì…œë¦¬ë‹˜, ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "invoke_graph(\n",
    "    agent,\n",
    "    inputs={\"messages\": [{\"role\": \"user\", \"content\": \"ë‚´ ì´ë¦„ì€ ì‚¬ì‹¤ ì…œë¦¬ì•¼\"}]},\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='ë‚´ ì´ë¦„ì€ í…Œë””ì•¼', additional_kwargs={}, response_metadata={}, id='fba17ade-3572-47b2-a939-70b10f8c7d19'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 87, 'total_tokens': 104, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-Cb48yvwIjmuerToKynHuxqLnvXMiD', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--ced8dc04-8ee6-486d-9fa2-6187f46dc220-0', tool_calls=[{'name': 'update_user_name', 'args': {'new_name': 'í…Œë””'}, 'id': 'call_8IpiHsQgS9fn0boyu48tEYce', 'type': 'tool_call'}], usage_metadata={'input_tokens': 87, 'output_tokens': 17, 'total_tokens': 104, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='Successfully updated user name to í…Œë””', name='update_user_name', id='2272d01f-b99b-4b8f-9a23-5e15503e9dcb', tool_call_id='call_8IpiHsQgS9fn0boyu48tEYce'),\n",
       " AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, í…Œë””ë‹˜! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 120, 'total_tokens': 135, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-Cb48zD7tQQWhCjAVcQvyA57KDU2si', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--f94ddef8-3fea-4f06-8920-a3b83f80a8d8-0', usage_metadata={'input_tokens': 120, 'output_tokens': 15, 'total_tokens': 135, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='ë‚´ ì´ë¦„ì€ ì‚¬ì‹¤ ì…œë¦¬ì•¼', additional_kwargs={}, response_metadata={}, id='fcd74c54-8120-4aca-8beb-53cc06327e7a'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 150, 'total_tokens': 167, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-Cb48zEH3toy86ZNwQH7DIwTZ3FXwr', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--eb414445-378d-430c-a834-b74c7cd2570c-0', tool_calls=[{'name': 'update_user_name', 'args': {'new_name': 'ì…œë¦¬'}, 'id': 'call_hxxyUlNbwu4vUWn16886zUaU', 'type': 'tool_call'}], usage_metadata={'input_tokens': 150, 'output_tokens': 17, 'total_tokens': 167, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='Successfully updated user name to ì…œë¦¬', name='update_user_name', id='11f94dc3-2a0d-4d4a-82cf-f572b802de54', tool_call_id='call_hxxyUlNbwu4vUWn16886zUaU'),\n",
       " AIMessage(content='ì´ë¦„ì„ ì…œë¦¬ë¡œ ë³€ê²½í–ˆì–´ìš”. ì…œë¦¬ë‹˜, ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 184, 'total_tokens': 209, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-Cb490SCAHCjZXn3IkP4eGQKxERQUQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--b48c06e3-7de0-4a6b-8a40-85c4c05f542a-0', usage_metadata={'input_tokens': 184, 'output_tokens': 25, 'total_tokens': 209, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = agent.get_state(config).values[\"messages\"]\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  clear_messages (call_oYy9f618hea7imUfwxxIdxkz)\n",
      " Call ID: call_oYy9f618hea7imUfwxxIdxkz\n",
      "  Args:\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: clear_messages\n",
      "\n",
      "Successfully cleared all previous messages. Total of 9 deleted messages.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "All previous messages in the conversation history have been cleared, except for this one. How can I assist you further?\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "invoke_graph(\n",
    "    agent,\n",
    "    inputs={\"messages\": [{\"role\": \"user\", \"content\": \"ë©”ì‹œì§€ ì „ë¶€ ì‚­ì œí•´ì¤˜\"}]},\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ì§€ê¸ˆì€ ì‚¬ìš©ìì˜ ì´ë¦„ì„ ì•Œê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ì›í•˜ì‹œë©´ ìƒˆ ì´ë¦„ì„ ì•Œë ¤ì£¼ì‹œë©´ ê¸°ì–µí•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ì´ë¦„ì„ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "invoke_graph(\n",
    "    agent,\n",
    "    inputs={\"messages\": [{\"role\": \"user\", \"content\": \"ë‚´ ì´ë¦„ì´ ì‚¬ì‹¤ ë­ë¼ê³  í–ˆì§€?\"}]},\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì»¨í…ìŠ¤íŠ¸\n",
    "\n",
    "`runtime.context`ë¥¼ í†µí•´ ì‚¬ìš©ì ID, ì„¸ì…˜ ì„¸ë¶€ ì •ë³´ ë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ë³„ êµ¬ì„±ê³¼ ê°™ì€ ë¶ˆë³€ êµ¬ì„± ë° ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your current balance is $5000. Is there anything else you would like to know or do?\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "# ì‚¬ìš©ì ë°ì´í„°ë² ì´ìŠ¤ ì‹œë®¬ë ˆì´ì…˜\n",
    "USER_DATABASE = {\n",
    "    \"user123\": {\n",
    "        \"name\": \"Alice Johnson\",\n",
    "        \"account_type\": \"Premium\",\n",
    "        \"balance\": 5000,\n",
    "        \"email\": \"alice@example.com\",\n",
    "    },\n",
    "    \"user456\": {\n",
    "        \"name\": \"Bob Smith\",\n",
    "        \"account_type\": \"Standard\",\n",
    "        \"balance\": 1200,\n",
    "        \"email\": \"bob@example.com\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class UserContext:\n",
    "    user_id: str\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_account_info(runtime: ToolRuntime[UserContext]) -> str:\n",
    "    \"\"\"Get the current user's account information.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "\n",
    "    if user_id in USER_DATABASE:\n",
    "        user = USER_DATABASE[user_id]\n",
    "        return f\"Account holder: {user['name']}\\nType: {user['account_type']}\\nBalance: ${user['balance']}\"\n",
    "    return \"User not found\"\n",
    "\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ìƒì„±\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[get_account_info],\n",
    "    context_schema=UserContext,\n",
    "    system_prompt=\"You are a financial assistant.\",\n",
    ")\n",
    "\n",
    "# ì»¨í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ ì—ì´ì „íŠ¸ ì‹¤í–‰\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my current balance?\"}]},\n",
    "    context=UserContext(user_id=\"user123\"),\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë©”ëª¨ë¦¬ (Store)\n",
    "\n",
    "ìŠ¤í† ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ì „ë°˜ì— ê±¸ì³ ì˜êµ¬ ë°ì´í„°ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìŠ¤í† ì–´ëŠ” `runtime.store`ë¥¼ í†µí•´ ì•¡ì„¸ìŠ¤ë˜ë©° ì‚¬ìš©ìë³„ ë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ë³„ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì ‘ê·¼\n",
    "@tool\n",
    "def get_user_info(user_id: str, runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Look up user info.\"\"\"\n",
    "    store = runtime.store\n",
    "    user_info = store.get((\"users\",), user_id)\n",
    "    return str(user_info.value) if user_info else \"Unknown user\"\n",
    "\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸\n",
    "@tool\n",
    "def save_user_info(\n",
    "    user_id: str, user_info: dict[str, Any], runtime: ToolRuntime\n",
    ") -> str:\n",
    "    \"\"\"Save user info.\"\"\"\n",
    "    store = runtime.store\n",
    "    store.put((\"users\",), user_id, user_info)\n",
    "    return \"Successfully saved user info.\"\n",
    "\n",
    "\n",
    "# ìŠ¤í† ì–´ì™€ ì—ì´ì „íŠ¸ ìƒì„±\n",
    "store = InMemoryStore()\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "agent = create_agent(model, tools=[get_user_info, save_user_info], store=store)\n",
    "\n",
    "# ì²« ë²ˆì§¸ ì„¸ì…˜: ì‚¬ìš©ì ì •ë³´ ì €ì¥\n",
    "print(\"=== Saving user info ===\")\n",
    "result1 = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Save the following user: userid: abc123, name: Foo, age: 25, email: foo@langchain.dev\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "print(result1[\"messages\"][-1].content)\n",
    "\n",
    "# ë‘ ë²ˆì§¸ ì„¸ì…˜: ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "print(\"\\n=== Getting user info ===\")\n",
    "result2 = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"Get user info for user with id 'abc123'\"}\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "print(result2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream Writer\n",
    "\n",
    "`runtime.stream_writer`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë„êµ¬ê°€ ì‹¤í–‰ë  ë•Œ ì»¤ìŠ¤í…€ ì—…ë°ì´íŠ¸ë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ë„êµ¬ê°€ ìˆ˜í–‰í•˜ëŠ” ì‘ì—…ì— ëŒ€í•´ ì‚¬ìš©ìì—ê²Œ ì‹¤ì‹œê°„ í”¼ë“œë°±ì„ ì œê³µí•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather_with_updates(city: str, runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    writer = runtime.stream_writer\n",
    "\n",
    "    # ë„êµ¬ê°€ ì‹¤í–‰ë  ë•Œ ì»¤ìŠ¤í…€ ì—…ë°ì´íŠ¸ ìŠ¤íŠ¸ë¦¬ë°\n",
    "    writer(f\"Looking up data for city: {city}\")\n",
    "    writer(f\"Acquired data for city: {city}\")\n",
    "\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "\n",
    "# ì°¸ê³ : runtime.stream_writerë¥¼ ë„êµ¬ ë‚´ì—ì„œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°,\n",
    "# ë„êµ¬ëŠ” LangGraph ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ ë‚´ì—ì„œ í˜¸ì¶œë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up data for city: ì„œìš¸\n",
      "Acquired data for city: ì„œìš¸\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.messages import stream_graph\n",
    "\n",
    "# ìŠ¤í† ì–´ì™€ ì—ì´ì „íŠ¸ ìƒì„±\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "agent = create_agent(model, tools=[get_weather_with_updates])\n",
    "\n",
    "inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"ì„œìš¸ ë‚ ì”¨ ì•Œë ¤ì¤˜\"}]}\n",
    "\n",
    "for chunk in agent.stream(inputs, stream_mode=\"custom\"):\n",
    "    print(chunk)\n",
    "\n",
    "# stream_graph(agent, inputs=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
