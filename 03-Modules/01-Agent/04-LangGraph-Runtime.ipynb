{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Runtime\n",
        "\n",
        "LangChainÏùò `create_agent`Îäî ÎÇ¥Î∂ÄÏ†ÅÏúºÎ°ú LangGraphÏùò Îü∞ÌÉÄÏûÑÏùÑ ÏÇ¨Ïö©Ìï©ÎãàÎã§.\n",
        "\n",
        "LangGraphÎäî Îã§Ïùå Ï†ïÎ≥¥Î•º Ìè¨Ìï®ÌïòÎäî `Runtime` Í∞ùÏ≤¥Î•º Ï†úÍ≥µÌï©ÎãàÎã§:\n",
        "\n",
        "1. **Context**: ÏÇ¨Ïö©Ïûê ID, Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞ ÎòêÎäî ÏóêÏù¥Ï†ÑÌä∏ Ìò∏Ï∂úÏùÑ ÏúÑÌïú Í∏∞ÌÉÄ Ï¢ÖÏÜçÏÑ±Í≥º Í∞ôÏùÄ Ï†ïÏ†Å Ï†ïÎ≥¥\n",
        "2. **Store**: Ïû•Í∏∞ Î©îÎ™®Î¶¨Î•º ÏúÑÌïú `BaseStore` Ïù∏Ïä§ÌÑ¥Ïä§\n",
        "3. **Stream writer**: `\"custom\"` Ïä§Ìä∏Î¶º Î™®ÎìúÎ•º ÌÜµÌï¥ Ï†ïÎ≥¥Î•º Ïä§Ìä∏Î¶¨Î∞çÌïòÎäî Îç∞ ÏÇ¨Ïö©ÎêòÎäî Í∞ùÏ≤¥\n",
        "\n",
        "Îü∞ÌÉÄÏûÑ Ï†ïÎ≥¥Îäî ÎèÑÍµ¨ÏôÄ ÎØ∏Îì§Ïõ®Ïñ¥ ÎÇ¥ÏóêÏÑú Ïï°ÏÑ∏Ïä§Ìï† Ïàò ÏûàÏäµÎãàÎã§."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ÏÇ¨Ï†Ñ Ï§ÄÎπÑ\n",
        "\n",
        "ÌôòÍ≤Ω Î≥ÄÏàòÎ•º ÏÑ§Ï†ïÌï©ÎãàÎã§."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Context Ï†ïÏùò Î∞è ÏÇ¨Ïö©\n",
        "\n",
        "`create_agent`Î°ú ÏóêÏù¥Ï†ÑÌä∏Î•º ÏÉùÏÑ±Ìï† Îïå `context_schema`Î•º ÏßÄÏ†ïÌïòÏó¨ ÏóêÏù¥Ï†ÑÌä∏ `Runtime`Ïóê Ï†ÄÏû•Îê† `context`Ïùò Íµ¨Ï°∞Î•º Ï†ïÏùòÌï† Ïàò ÏûàÏäµÎãàÎã§."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I don't have access to your name. Could you please tell me your name?\n"
          ]
        }
      ],
      "source": [
        "from dataclasses import dataclass\n",
        "from langchain.agents import create_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.tools import tool\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Context:\n",
        "    user_name: str\n",
        "\n",
        "\n",
        "@tool\n",
        "def greet_user() -> str:\n",
        "    \"\"\"Greet the user.\"\"\"\n",
        "    return \"Hello!\"\n",
        "\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
        "\n",
        "agent = create_agent(\n",
        "    model=model, tools=[greet_user], context_schema=Context  # Context Ïä§ÌÇ§Îßà Ï†ïÏùò\n",
        ")\n",
        "\n",
        "# ContextÎ•º Ï†ÑÎã¨ÌïòÏó¨ ÏóêÏù¥Ï†ÑÌä∏ Ìò∏Ï∂ú\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my name?\"}]},\n",
        "    context=Context(user_name=\"John Smith\"),  # Context Ï†ÑÎã¨\n",
        ")\n",
        "\n",
        "print(result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ÎèÑÍµ¨ÏóêÏÑú Runtime Ïï°ÏÑ∏Ïä§\n",
        "\n",
        "ÎèÑÍµ¨ ÎÇ¥ÏóêÏÑú Îü∞ÌÉÄÏûÑ Ï†ïÎ≥¥Ïóê Ïï°ÏÑ∏Ïä§ÌïòÏó¨ Îã§ÏùåÏùÑ ÏàòÌñâÌï† Ïàò ÏûàÏäµÎãàÎã§:\n",
        "\n",
        "- ContextÏóê Ïï°ÏÑ∏Ïä§\n",
        "- Ïû•Í∏∞ Î©îÎ™®Î¶¨ ÏùΩÍ∏∞ ÎòêÎäî Ïì∞Í∏∞\n",
        "- Ïª§Ïä§ÌÖÄ Ïä§Ìä∏Î¶ºÏóê Ïì∞Í∏∞ (Ïòà: ÎèÑÍµ¨ ÏßÑÌñâ ÏÉÅÌô©/ÏóÖÎç∞Ïù¥Ìä∏)\n",
        "\n",
        "`ToolRuntime` Îß§Í∞úÎ≥ÄÏàòÎ•º ÏÇ¨Ïö©ÌïòÏó¨ ÎèÑÍµ¨ ÎÇ¥ÏóêÏÑú `Runtime` Í∞ùÏ≤¥Ïóê Ïï°ÏÑ∏Ïä§Ìï©ÎãàÎã§."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Context Ïï°ÏÑ∏Ïä§"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.tools import tool, ToolRuntime\n",
        "from dataclasses import dataclass\n",
        "from langchain_teddynote.messages import invoke_graph\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class UserContext:\n",
        "    user_id: str\n",
        "    user_name: str\n",
        "    user_email: str\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_user_info(runtime: ToolRuntime[UserContext]) -> str:\n",
        "    \"\"\"Get information about the current user.\"\"\"\n",
        "    # ContextÏóêÏÑú ÏÇ¨Ïö©Ïûê Ï†ïÎ≥¥ Í∞ÄÏ†∏Ïò§Í∏∞\n",
        "    user_id = runtime.context.user_id\n",
        "    user_name = runtime.context.user_name\n",
        "    user_email = runtime.context.user_email\n",
        "\n",
        "    return f\"User ID: {user_id}, Name: {user_name}, Email: {user_email}\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def personalized_greeting(runtime: ToolRuntime[UserContext]) -> str:\n",
        "    \"\"\"Generate a personalized greeting for the user.\"\"\"\n",
        "    user_name = runtime.context.user_name\n",
        "    return f\"ÏïàÎÖïÌïòÏÑ∏Ïöî, {user_name}Îãò! Î¨¥ÏóáÏùÑ ÎèÑÏôÄÎìúÎ¶¥ÍπåÏöî?\"\n",
        "\n",
        "\n",
        "agent = create_agent(\n",
        "    model=model,\n",
        "    tools=[get_user_info, personalized_greeting],\n",
        "    context_schema=UserContext,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "üîÑ Node: \u001b[1;36mmodel\u001b[0m üîÑ\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  get_user_info (call_aCCGYgoqyD3iBVtKs0lnPdEK)\n",
            " Call ID: call_aCCGYgoqyD3iBVtKs0lnPdEK\n",
            "  Args:\n",
            "  personalized_greeting (call_9Xzn8buotGRVJAIqj406k5AB)\n",
            " Call ID: call_9Xzn8buotGRVJAIqj406k5AB\n",
            "  Args:\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "üîÑ Node: \u001b[1;36mtools\u001b[0m üîÑ\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: get_user_info\n",
            "\n",
            "User ID: user_123, Name: ÍπÄÏ≤†Ïàò, Email: chulsoo@example.com\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "üîÑ Node: \u001b[1;36mtools\u001b[0m üîÑ\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: personalized_greeting\n",
            "\n",
            "ÏïàÎÖïÌïòÏÑ∏Ïöî, ÍπÄÏ≤†ÏàòÎãò! Î¨¥ÏóáÏùÑ ÎèÑÏôÄÎìúÎ¶¥ÍπåÏöî?\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "üîÑ Node: \u001b[1;36mmodel\u001b[0m üîÑ\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "ÏïàÎÖïÌïòÏÑ∏Ïöî, ÍπÄÏ≤†ÏàòÎãò! Î∞òÍ∞ëÏäµÎãàÎã§. Î¨¥ÏóáÏùÑ ÎèÑÏôÄÎìúÎ¶¥ÍπåÏöî?\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# ContextÎ•º Ï†ÑÎã¨ÌïòÏó¨ Ìò∏Ï∂ú\n",
        "invoke_graph(\n",
        "    agent,\n",
        "    inputs={\"messages\": [{\"role\": \"user\", \"content\": \"ÏïàÎÖïÌïòÏÑ∏Ïöî? Î∞òÍ∞ëÏäµÎãàÎã§.\"}]},\n",
        "    context=UserContext(\n",
        "        user_id=\"user_123\", user_name=\"ÍπÄÏ≤†Ïàò\", user_email=\"chulsoo@example.com\"\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Store Ïï°ÏÑ∏Ïä§ (Ïû•Í∏∞ Î©îÎ™®Î¶¨)\n",
        "\n",
        "ÎèÑÍµ¨ ÎÇ¥ÏóêÏÑú StoreÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Ïû•Í∏∞ Î©îÎ™®Î¶¨Ïóê Ïï°ÏÑ∏Ïä§Ìï† Ïàò ÏûàÏäµÎãàÎã§."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from langchain.tools import tool, ToolRuntime\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Context:\n",
        "    user_id: str\n",
        "\n",
        "\n",
        "@tool\n",
        "def fetch_user_email_preferences(runtime: ToolRuntime[Context]) -> str:\n",
        "    \"\"\"Fetch the user's email preferences from the store.\"\"\"\n",
        "    user_id = runtime.context.user_id\n",
        "\n",
        "    # Í∏∞Î≥∏ ÏÑ§Ï†ï\n",
        "    preferences: str = \"The user prefers you to write a brief and polite email.\"\n",
        "\n",
        "    # StoreÏóêÏÑú ÏÇ¨Ïö©Ïûê ÏÑ§Ï†ï Í∞ÄÏ†∏Ïò§Í∏∞\n",
        "    if runtime.store:\n",
        "        if memory := runtime.store.get((\"users\",), user_id):\n",
        "            preferences = memory.value[\"preferences\"]\n",
        "\n",
        "    return preferences\n",
        "\n",
        "\n",
        "@tool\n",
        "def save_user_preference(preference: str, runtime: ToolRuntime[Context]) -> str:\n",
        "    \"\"\"Save user preference to the store.\"\"\"\n",
        "    user_id = runtime.context.user_id\n",
        "\n",
        "    if runtime.store:\n",
        "        runtime.store.put((\"users\",), user_id, {\"preferences\": preference})\n",
        "        return f\"Saved preference: {preference}\"\n",
        "\n",
        "    return \"Store not available\"\n",
        "\n",
        "\n",
        "# StoreÏôÄ Ìï®Íªò ÏóêÏù¥Ï†ÑÌä∏ ÏÉùÏÑ±\n",
        "store = InMemoryStore()\n",
        "\n",
        "# Ï¥àÍ∏∞ Îç∞Ïù¥ÌÑ∞ ÏÑ§Ï†ï\n",
        "store.put(\n",
        "    (\"users\",),\n",
        "    \"user_123\",\n",
        "    {\"preferences\": \"The user prefers detailed and technical explanations.\"},\n",
        ")\n",
        "\n",
        "agent = create_agent(\n",
        "    model=model,\n",
        "    tools=[fetch_user_email_preferences, save_user_preference],\n",
        "    context_schema=Context,\n",
        "    store=store,  # Store Ï†ÑÎã¨\n",
        ")\n",
        "\n",
        "# StoreÏóêÏÑú ÏÑ§Ï†ï Í∞ÄÏ†∏Ïò§Í∏∞\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"What are my email preferences?\"}]},\n",
        "    context=Context(user_id=\"user_123\"),\n",
        ")\n",
        "\n",
        "print(result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stream Writer Ïï°ÏÑ∏Ïä§\n",
        "\n",
        "ÎèÑÍµ¨ ÎÇ¥ÏóêÏÑú Stream WriterÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Ïª§Ïä§ÌÖÄ ÏóÖÎç∞Ïù¥Ìä∏Î•º Ïä§Ìä∏Î¶¨Î∞çÌï† Ïàò ÏûàÏäµÎãàÎã§."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.tools import tool, ToolRuntime\n",
        "import time\n",
        "\n",
        "\n",
        "@tool\n",
        "def process_large_dataset(num_items: int, runtime: ToolRuntime) -> str:\n",
        "    \"\"\"Process a large dataset and report progress.\"\"\"\n",
        "    writer = runtime.get_stream_writer()\n",
        "\n",
        "    # ÏßÑÌñâ ÏÉÅÌô© Ïä§Ìä∏Î¶¨Î∞ç\n",
        "    for i in range(0, num_items, 10):\n",
        "        progress = min(i + 10, num_items)\n",
        "        writer({\"stage\": \"processing\", \"progress\": progress, \"total\": num_items})\n",
        "        time.sleep(0.1)  # ÏûëÏóÖ ÏãúÎÆ¨Î†àÏù¥ÏÖò\n",
        "\n",
        "    writer({\"stage\": \"completed\", \"total\": num_items})\n",
        "    return f\"Successfully processed {num_items} items!\"\n",
        "\n",
        "\n",
        "agent = create_agent(\n",
        "    model=model,\n",
        "    tools=[process_large_dataset],\n",
        ")\n",
        "\n",
        "# Ïª§Ïä§ÌÖÄ Ïä§Ìä∏Î¶º Î™®ÎìúÎ°ú ÏßÑÌñâ ÏÉÅÌô© Ï∂îÏ†Å\n",
        "for chunk in agent.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"Process 50 items\"}]},\n",
        "    stream_mode=\"custom\",\n",
        "):\n",
        "    if \"progress\" in chunk:\n",
        "        percentage = (chunk[\"progress\"] / chunk[\"total\"]) * 100\n",
        "        print(f\"Progress: {percentage:.0f}%\")\n",
        "    elif \"stage\" in chunk and chunk[\"stage\"] == \"completed\":\n",
        "        print(f\"Completed processing {chunk['total']} items!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ÎØ∏Îì§Ïõ®Ïñ¥ÏóêÏÑú Runtime Ïï°ÏÑ∏Ïä§\n",
        "\n",
        "ÎØ∏Îì§Ïõ®Ïñ¥ÏóêÏÑú Îü∞ÌÉÄÏûÑ Ï†ïÎ≥¥Ïóê Ïï°ÏÑ∏Ïä§ÌïòÏó¨ ÎèôÏ†Å ÌîÑÎ°¨ÌîÑÌä∏Î•º ÏÉùÏÑ±ÌïòÍ±∞ÎÇò, Î©îÏãúÏßÄÎ•º ÏàòÏ†ïÌïòÍ±∞ÎÇò, ÏÇ¨Ïö©Ïûê Ïª®ÌÖçÏä§Ìä∏Ïóê Îî∞Îùº ÏóêÏù¥Ï†ÑÌä∏ ÎèôÏûëÏùÑ Ï†úÏñ¥Ìï† Ïàò ÏûàÏäµÎãàÎã§."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dynamic PromptÏóêÏÑú Runtime ÏÇ¨Ïö©"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from langchain.agents import create_agent\n",
        "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
        "from langchain.tools import tool\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Context:\n",
        "    user_name: str\n",
        "    user_role: str\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Get the weather in a city.\"\"\"\n",
        "    return f\"The weather in {city} is sunny!\"\n",
        "\n",
        "\n",
        "@dynamic_prompt\n",
        "def dynamic_system_prompt(request: ModelRequest) -> str:\n",
        "    # RuntimeÏóêÏÑú Context Í∞ÄÏ†∏Ïò§Í∏∞\n",
        "    user_name = request.runtime.context.user_name\n",
        "    user_role = request.runtime.context.user_role\n",
        "\n",
        "    # ÏÇ¨Ïö©Ïûê Ïó≠Ìï†Ïóê Îî∞Îùº Îã§Î•∏ ÌîÑÎ°¨ÌîÑÌä∏\n",
        "    if user_role == \"admin\":\n",
        "        system_prompt = f\"You are a helpful assistant with full access. Address the user as {user_name}.\"\n",
        "    else:\n",
        "        system_prompt = f\"You are a helpful assistant. Address the user as {user_name}. Provide brief answers.\"\n",
        "\n",
        "    return system_prompt\n",
        "\n",
        "\n",
        "agent = create_agent(\n",
        "    model=model,\n",
        "    tools=[get_weather],\n",
        "    middleware=[dynamic_system_prompt],\n",
        "    context_schema=Context,\n",
        ")\n",
        "\n",
        "# Admin ÏÇ¨Ïö©ÏûêÎ°ú Ìò∏Ï∂ú\n",
        "print(\"=== Admin User ===\")\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
        "    context=Context(user_name=\"Admin Kim\", user_role=\"admin\"),\n",
        ")\n",
        "print(result[\"messages\"][-1].content)\n",
        "\n",
        "# ÏùºÎ∞ò ÏÇ¨Ïö©ÏûêÎ°ú Ìò∏Ï∂ú\n",
        "print(\"\\n=== Regular User ===\")\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
        "    context=Context(user_name=\"User Lee\", user_role=\"user\"),\n",
        ")\n",
        "print(result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Before/After ModelÏóêÏÑú Runtime ÏÇ¨Ïö©"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import AgentState\n",
        "from langchain.agents.middleware import before_model, after_model\n",
        "from langgraph.runtime import Runtime\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Context:\n",
        "    user_name: str\n",
        "    session_id: str\n",
        "\n",
        "\n",
        "@before_model\n",
        "def log_before_model(state: AgentState, runtime: Runtime[Context]) -> dict | None:\n",
        "    \"\"\"Î™®Îç∏ Ìò∏Ï∂ú Ï†Ñ Î°úÍπÖ\"\"\"\n",
        "    print(\n",
        "        f\"[Before Model] User: {runtime.context.user_name}, Session: {runtime.context.session_id}\"\n",
        "    )\n",
        "    print(f\"[Before Model] Messages count: {len(state['messages'])}\")\n",
        "    return None\n",
        "\n",
        "\n",
        "@after_model\n",
        "def log_after_model(state: AgentState, runtime: Runtime[Context]) -> dict | None:\n",
        "    \"\"\"Î™®Îç∏ Ìò∏Ï∂ú ÌõÑ Î°úÍπÖ\"\"\"\n",
        "    print(f\"[After Model] User: {runtime.context.user_name}\")\n",
        "    print(f\"[After Model] Response generated for session: {runtime.context.session_id}\")\n",
        "    return None\n",
        "\n",
        "\n",
        "agent = create_agent(\n",
        "    model=model,\n",
        "    tools=[get_weather],\n",
        "    middleware=[log_before_model, log_after_model],\n",
        "    context_schema=Context,\n",
        ")\n",
        "\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's the weather in Seoul?\"}]},\n",
        "    context=Context(user_name=\"John Smith\", session_id=\"session_456\"),\n",
        ")\n",
        "\n",
        "print(f\"\\nFinal response: {result['messages'][-1].content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ï¢ÖÌï© ÏòàÏ†ú: ÏÇ¨Ïö©Ïûê Ïª®ÌÖçÏä§Ìä∏ Í∏∞Î∞ò ÏóêÏù¥Ï†ÑÌä∏\n",
        "\n",
        "RuntimeÏùò Î™®Îì† Í∏∞Îä•ÏùÑ ÌôúÏö©Ìïú Ïã§Ïö©Ï†ÅÏù∏ ÏòàÏ†úÏûÖÎãàÎã§."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from langchain.agents import create_agent, AgentState\n",
        "from langchain.agents.middleware import dynamic_prompt, ModelRequest, before_model\n",
        "from langchain.tools import tool, ToolRuntime\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "from langgraph.runtime import Runtime\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class UserContext:\n",
        "    user_id: str\n",
        "    user_name: str\n",
        "    user_tier: str  # \"free\", \"premium\", \"enterprise\"\n",
        "    language: str  # \"ko\", \"en\"\n",
        "\n",
        "\n",
        "# ÎèÑÍµ¨ Ï†ïÏùò\n",
        "@tool\n",
        "def search_database(query: str, runtime: ToolRuntime[UserContext]) -> str:\n",
        "    \"\"\"Search the database. Access level depends on user tier.\"\"\"\n",
        "    user_tier = runtime.context.user_tier\n",
        "\n",
        "    # ÏÇ¨Ïö©Ïûê Îì±Í∏âÏóê Îî∞Îùº Îã§Î•∏ Í≤∞Í≥º Ï†úÍ≥µ\n",
        "    if user_tier == \"enterprise\":\n",
        "        return f\"Full database search results for: {query} (Enterprise access)\"\n",
        "    elif user_tier == \"premium\":\n",
        "        return f\"Premium search results for: {query}\"\n",
        "    else:\n",
        "        return f\"Basic search results for: {query} (Limited to 10 results)\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_user_history(runtime: ToolRuntime[UserContext]) -> str:\n",
        "    \"\"\"Get user's search history from store.\"\"\"\n",
        "    user_id = runtime.context.user_id\n",
        "\n",
        "    if runtime.store:\n",
        "        if history := runtime.store.get((\"history\",), user_id):\n",
        "            return f\"Recent searches: {history.value['searches']}\"\n",
        "\n",
        "    return \"No search history found\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def save_search(query: str, runtime: ToolRuntime[UserContext]) -> str:\n",
        "    \"\"\"Save search query to user history.\"\"\"\n",
        "    user_id = runtime.context.user_id\n",
        "\n",
        "    if runtime.store:\n",
        "        # Í∏∞Ï°¥ ÌûàÏä§ÌÜ†Î¶¨ Í∞ÄÏ†∏Ïò§Í∏∞\n",
        "        existing = runtime.store.get((\"history\",), user_id)\n",
        "        searches = existing.value[\"searches\"] if existing else []\n",
        "\n",
        "        # ÏÉà Í≤ÄÏÉâÏñ¥ Ï∂îÍ∞Ä\n",
        "        searches.append(query)\n",
        "        runtime.store.put(\n",
        "            (\"history\",), user_id, {\"searches\": searches[-5:]}\n",
        "        )  # ÏµúÍ∑º 5Í∞úÎßå Ïú†ÏßÄ\n",
        "\n",
        "        return f\"Saved search: {query}\"\n",
        "\n",
        "    return \"Store not available\"\n",
        "\n",
        "\n",
        "# ÎèôÏ†Å ÌîÑÎ°¨ÌîÑÌä∏ - ÏÇ¨Ïö©Ïûê Ïñ∏Ïñ¥Ïóê Îî∞Îùº Î≥ÄÍ≤Ω\n",
        "@dynamic_prompt\n",
        "def multilingual_prompt(request: ModelRequest) -> str:\n",
        "    user_name = request.runtime.context.user_name\n",
        "    language = request.runtime.context.language\n",
        "    user_tier = request.runtime.context.user_tier\n",
        "\n",
        "    if language == \"ko\":\n",
        "        prompt = f\"ÎãπÏã†ÏùÄ ÎèÑÏõÄÏù¥ ÎêòÎäî Ïñ¥ÏãúÏä§ÌÑ¥Ìä∏ÏûÖÎãàÎã§. ÏÇ¨Ïö©ÏûêÎ•º '{user_name}'ÎãòÏúºÎ°ú Ìò∏Ïπ≠ÌïòÏÑ∏Ïöî.\"\n",
        "        if user_tier == \"enterprise\":\n",
        "            prompt += (\n",
        "                \" Ïù¥ ÏÇ¨Ïö©ÏûêÎäî ÏóîÌÑ∞ÌîÑÎùºÏù¥Ï¶à ÌöåÏõêÏù¥ÎØÄÎ°ú Î™®Îì† Í∏∞Îä•Ïóê Ïï°ÏÑ∏Ïä§Ìï† Ïàò ÏûàÏäµÎãàÎã§.\"\n",
        "            )\n",
        "    else:\n",
        "        prompt = f\"You are a helpful assistant. Address the user as {user_name}.\"\n",
        "        if user_tier == \"enterprise\":\n",
        "            prompt += \" This is an enterprise user with full access.\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "\n",
        "# ÏÇ¨Ïö©Îüâ Ï∂îÏ†Å ÎØ∏Îì§Ïõ®Ïñ¥\n",
        "@before_model\n",
        "def track_usage(state: AgentState, runtime: Runtime[UserContext]) -> dict | None:\n",
        "    \"\"\"Track API usage for billing\"\"\"\n",
        "    user_id = runtime.context.user_id\n",
        "    user_tier = runtime.context.user_tier\n",
        "\n",
        "    print(f\"[Usage Tracker] User: {user_id}, Tier: {user_tier}\")\n",
        "\n",
        "    # Î¨¥Î£å ÏÇ¨Ïö©ÏûêÏùò Í≤ΩÏö∞ ÏÇ¨Ïö©Îüâ Ï†úÌïú ÌôïÏù∏\n",
        "    if user_tier == \"free\":\n",
        "        if runtime.store:\n",
        "            usage = runtime.store.get((\"usage\",), user_id)\n",
        "            count = usage.value[\"count\"] if usage else 0\n",
        "\n",
        "            if count >= 10:\n",
        "                print(\"[Usage Tracker] Free tier limit reached!\")\n",
        "                # Ïã§Ï†úÎ°úÎäî Ïó¨Í∏∞ÏÑú Ïã§ÌñâÏùÑ Ï§ëÎã®Ìï† Ïàò ÏûàÏùå\n",
        "\n",
        "            # ÏÇ¨Ïö©Îüâ ÏóÖÎç∞Ïù¥Ìä∏\n",
        "            runtime.store.put((\"usage\",), user_id, {\"count\": count + 1})\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "# Store ÏÉùÏÑ± Î∞è Ï¥àÍ∏∞ Îç∞Ïù¥ÌÑ∞ ÏÑ§Ï†ï\n",
        "store = InMemoryStore()\n",
        "store.put(\n",
        "    (\"history\",), \"user_001\", {\"searches\": [\"Python tutorial\", \"LangChain guide\"]}\n",
        ")\n",
        "store.put((\"usage\",), \"user_002\", {\"count\": 5})\n",
        "\n",
        "# ÏóêÏù¥Ï†ÑÌä∏ ÏÉùÏÑ±\n",
        "agent = create_agent(\n",
        "    model=model,\n",
        "    tools=[search_database, get_user_history, save_search],\n",
        "    middleware=[multilingual_prompt, track_usage],\n",
        "    context_schema=UserContext,\n",
        "    store=store,\n",
        ")\n",
        "\n",
        "# ÌÖåÏä§Ìä∏ 1: ÏóîÌÑ∞ÌîÑÎùºÏù¥Ï¶à ÏÇ¨Ïö©Ïûê (ÌïúÍµ≠Ïñ¥)\n",
        "print(\"=== Test 1: Enterprise User (Korean) ===\")\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"Search for 'machine learning'\"}]},\n",
        "    context=UserContext(\n",
        "        user_id=\"user_001\", user_name=\"ÍπÄÏ≤†Ïàò\", user_tier=\"enterprise\", language=\"ko\"\n",
        "    ),\n",
        ")\n",
        "print(result[\"messages\"][-1].content)\n",
        "\n",
        "# ÌÖåÏä§Ìä∏ 2: Î¨¥Î£å ÏÇ¨Ïö©Ïûê (ÏòÅÏñ¥)\n",
        "print(\"\\n=== Test 2: Free User (English) ===\")\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"Search for 'data science'\"}]},\n",
        "    context=UserContext(\n",
        "        user_id=\"user_002\", user_name=\"John Doe\", user_tier=\"free\", language=\"en\"\n",
        "    ),\n",
        ")\n",
        "print(result[\"messages\"][-1].content)\n",
        "\n",
        "# ÌÖåÏä§Ìä∏ 3: Í≤ÄÏÉâ Í∏∞Î°ù Ï°∞Ìöå\n",
        "print(\"\\n=== Test 3: Check Search History ===\")\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my search history?\"}]},\n",
        "    context=UserContext(\n",
        "        user_id=\"user_001\", user_name=\"ÍπÄÏ≤†Ïàò\", user_tier=\"enterprise\", language=\"ko\"\n",
        "    ),\n",
        ")\n",
        "print(result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ïã§Ï†Ñ Ìå®ÌÑ¥\n",
        "\n",
        "### 1. Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞ Ï†ÑÎã¨\n",
        "\n",
        "ContextÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞ÏùÑ ÎèÑÍµ¨Ïóê Ï†ÑÎã¨Ìï† Ïàò ÏûàÏäµÎãàÎã§."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Any\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DatabaseContext:\n",
        "    db_connection: Any  # Ïã§Ï†úÎ°úÎäî Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞ Í∞ùÏ≤¥\n",
        "    user_id: str\n",
        "\n",
        "\n",
        "@tool\n",
        "def query_database(sql: str, runtime: ToolRuntime[DatabaseContext]) -> str:\n",
        "    \"\"\"Execute SQL query on the database.\"\"\"\n",
        "    db = runtime.context.db_connection\n",
        "    user_id = runtime.context.user_id\n",
        "\n",
        "    # Ïã§Ï†ú Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÏøºÎ¶¨ Ïã§Ìñâ\n",
        "    # result = db.execute(sql)\n",
        "\n",
        "    return f\"Query executed for user {user_id}: {sql}\"\n",
        "\n",
        "\n",
        "# ÏÇ¨Ïö© ÏòàÏãú (Ïã§Ï†ú DB Ïó∞Í≤∞ ÎåÄÏã† None ÏÇ¨Ïö©)\n",
        "# agent = create_agent(\n",
        "#     model=model,\n",
        "#     tools=[query_database],\n",
        "#     context_schema=DatabaseContext\n",
        "# )\n",
        "#\n",
        "# result = agent.invoke(\n",
        "#     {\"messages\": [{\"role\": \"user\", \"content\": \"Query user data\"}]},\n",
        "#     context=DatabaseContext(db_connection=db, user_id=\"user_123\")\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Ïù∏Ï¶ù Î∞è Í∂åÌïú Í≤ÄÏÇ¨\n",
        "\n",
        "ÎØ∏Îì§Ïõ®Ïñ¥ÏóêÏÑú ContextÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Ïù∏Ï¶ù Î∞è Í∂åÌïúÏùÑ Í≤ÄÏÇ¨Ìï† Ïàò ÏûàÏäµÎãàÎã§."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents.middleware import before_agent, hook_config\n",
        "from typing import Any\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class AuthContext:\n",
        "    user_id: str\n",
        "    permissions: list[str]\n",
        "\n",
        "\n",
        "@before_agent(can_jump_to=[\"end\"])\n",
        "def check_permissions(\n",
        "    state: AgentState, runtime: Runtime[AuthContext]\n",
        ") -> dict[str, Any] | None:\n",
        "    \"\"\"Check if user has required permissions\"\"\"\n",
        "    permissions = runtime.context.permissions\n",
        "\n",
        "    # Î©îÏãúÏßÄÏóêÏÑú ÏöîÏ≤≠Îêú ÏûëÏóÖ ÌôïÏù∏\n",
        "    if state[\"messages\"]:\n",
        "        content = state[\"messages\"][0].content.lower()\n",
        "\n",
        "        # Í¥ÄÎ¶¨Ïûê ÏûëÏóÖ ÏöîÏ≤≠ Ïãú Í∂åÌïú ÌôïÏù∏\n",
        "        if \"delete\" in content or \"remove\" in content:\n",
        "            if \"admin\" not in permissions:\n",
        "                return {\n",
        "                    \"messages\": [\n",
        "                        {\n",
        "                            \"role\": \"assistant\",\n",
        "                            \"content\": \"You don't have permission to perform this action.\",\n",
        "                        }\n",
        "                    ],\n",
        "                    \"jump_to\": \"end\",\n",
        "                }\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "# ÏÇ¨Ïö© ÏòàÏãú\n",
        "# agent = create_agent(\n",
        "#     model=model,\n",
        "#     tools=[search_tool],\n",
        "#     middleware=[check_permissions],\n",
        "#     context_schema=AuthContext\n",
        "# )\n",
        "#\n",
        "# result = agent.invoke(\n",
        "#     {\"messages\": [{\"role\": \"user\", \"content\": \"Delete user data\"}]},\n",
        "#     context=AuthContext(user_id=\"user_123\", permissions=[\"read\", \"write\"])\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. ÏöîÏ≤≠Î≥Ñ ÏÑ§Ï†ï\n",
        "\n",
        "Í∞Å ÏöîÏ≤≠Ïóê ÎåÄÌïú ÌäπÏ†ï ÏÑ§Ï†ïÏùÑ ContextÎ•º ÌÜµÌï¥ Ï†ÑÎã¨Ìï† Ïàò ÏûàÏäµÎãàÎã§."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class RequestContext:\n",
        "    user_id: str\n",
        "    verbose: bool\n",
        "    timeout: int\n",
        "    max_tokens: int\n",
        "\n",
        "\n",
        "@tool\n",
        "def process_request(query: str, runtime: ToolRuntime[RequestContext]) -> str:\n",
        "    \"\"\"Process request with custom settings.\"\"\"\n",
        "    verbose = runtime.context.verbose\n",
        "    timeout = runtime.context.timeout\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Processing with timeout: {timeout}s\")\n",
        "\n",
        "    # ÏÑ§Ï†ïÏóê Îî∞Îùº Ï≤òÎ¶¨\n",
        "    return f\"Processed: {query}\"\n",
        "\n",
        "\n",
        "agent = create_agent(\n",
        "    model=model, tools=[process_request], context_schema=RequestContext\n",
        ")\n",
        "\n",
        "# ÏöîÏ≤≠Î≥ÑÎ°ú Îã§Î•∏ ÏÑ§Ï†ï ÏÇ¨Ïö©\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"Process my request\"}]},\n",
        "    context=RequestContext(\n",
        "        user_id=\"user_123\", verbose=True, timeout=30, max_tokens=1000\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(result[\"messages\"][-1].content)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
