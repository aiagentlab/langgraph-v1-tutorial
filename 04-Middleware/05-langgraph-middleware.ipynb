{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ë¯¸ë“¤ì›¨ì–´(Middleware)\n",
                "\n",
                "ë¯¸ë“¤ì›¨ì–´ëŠ” ì—ì´ì „íŠ¸ ì‹¤í–‰ì˜ ëª¨ë“  ë‹¨ê³„ë¥¼ ì œì–´í•˜ê³  ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ëŠ” ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
                "\n",
                "í•µì‹¬ ì—ì´ì „íŠ¸ ë£¨í”„ëŠ” ëª¨ë¸ì„ í˜¸ì¶œí•˜ê³ , ëª¨ë¸ì´ ì‹¤í–‰í•  ë„êµ¬ë¥¼ ì„ íƒí•˜ë„ë¡ í•œ ë‹¤ìŒ, ë” ì´ìƒ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì§€ ì•Šìœ¼ë©´ ì¢…ë£Œí•˜ëŠ” ê²ƒì„ í¬í•¨í•©ë‹ˆë‹¤.\n",
                "\n",
                "![](./assets/langgraph-middleware.avif)\n",
                "\n",
                "ë¯¸ë“¤ì›¨ì–´ëŠ” ê° ë‹¨ê³„ ì „í›„ì— í›„í¬ë¥¼ ë…¸ì¶œí•©ë‹ˆë‹¤.\n",
                "\n",
                "- ì—ì´ì „íŠ¸ ì‹œì‘ ì „/í›„\n",
                "- ëª¨ë¸ í˜¸ì¶œ ì „/í›„\n",
                "- ë„êµ¬ ì‹¤í–‰ ì „/í›„"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ì‚¬ì „ ì¤€ë¹„\n",
                "\n",
                "í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from dotenv import load_dotenv\n",
                "\n",
                "load_dotenv(override=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
                        "[í”„ë¡œì íŠ¸ëª…]\n",
                        "LangChain-V1-Tutorial\n"
                    ]
                }
            ],
            "source": [
                "from langchain_teddynote import logging\n",
                "\n",
                "logging.langsmith(\"LangChain-V1-Tutorial\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ë¯¸ë“¤ì›¨ì–´ê°€ í•  ìˆ˜ ìˆëŠ” ê²ƒ\n",
                "\n",
                "ë¯¸ë“¤ì›¨ì–´ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë‹¤ì–‘í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
                "\n",
                "- **ëª¨ë‹ˆí„°ë§** - ë¡œê¹…, ë¶„ì„ ë° ë””ë²„ê¹…ìœ¼ë¡œ ì—ì´ì „íŠ¸ ë™ì‘ ì¶”ì \n",
                "- **ìˆ˜ì •** - í”„ë¡¬í”„íŠ¸, ë„êµ¬ ì„ íƒ ë° ì¶œë ¥ í˜•ì‹ ë³€í™˜\n",
                "- **ì œì–´** - ì¬ì‹œë„, í´ë°± ë° ì¡°ê¸° ì¢…ë£Œ ë¡œì§ ì¶”ê°€\n",
                "- **ê°•ì œ** - ì†ë„ ì œí•œ, ê°€ë“œë ˆì¼ ë° PII ê°ì§€ ì ìš©"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ê¸°ë³¸ ì˜ˆì œ\n",
                "\n",
                "ë¯¸ë“¤ì›¨ì–´ë¥¼ ì¶”ê°€í•˜ë ¤ë©´ `create_agent`ì— ì „ë‹¬í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "==================================================\n",
                        "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
                        "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
                        "\n",
                        "==================================================\n",
                        "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m ğŸ”„\n",
                        "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
                        "It's sunny in Seoul!\n",
                        "==================================================\n",
                        "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
                        "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
                        "The weather in Seoul is sunny. Is there anything else you would like to know?"
                    ]
                }
            ],
            "source": [
                "from langchain.agents import create_agent\n",
                "from langchain_openai import ChatOpenAI\n",
                "from langchain.tools import tool\n",
                "from langchain_teddynote.messages import stream_graph\n",
                "from langchain_core.runnables import RunnableConfig\n",
                "\n",
                "\n",
                "# ê°„ë‹¨í•œ ë„êµ¬ ì •ì˜\n",
                "@tool\n",
                "def get_weather(city: str) -> str:\n",
                "    \"\"\"Get the weather for a given city.\"\"\"\n",
                "    return f\"It's sunny in {city}!\"\n",
                "\n",
                "\n",
                "# ëª¨ë¸ ë° ì—ì´ì „íŠ¸ ìƒì„±\n",
                "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
                "agent = create_agent(\n",
                "    model=model,\n",
                "    tools=[get_weather],\n",
                "    middleware=[],  # ì—¬ê¸°ì— ë¯¸ë“¤ì›¨ì–´ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤\n",
                ")\n",
                "\n",
                "# ì—ì´ì „íŠ¸ ì‹¤í–‰\n",
                "stream_graph(\n",
                "    agent,\n",
                "    inputs={\"messages\": [{\"role\": \"user\", \"content\": \"What's the weather in Seoul?\"}]},\n",
                "    config=RunnableConfig(),\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ë‚´ì¥ ë¯¸ë“¤ì›¨ì–´\n",
                "\n",
                "LangChainì€ ì¼ë°˜ì ì¸ ì‚¬ìš© ì‚¬ë¡€ë¥¼ ìœ„í•œ ì‚¬ì „ êµ¬ì¶•ëœ ë¯¸ë“¤ì›¨ì–´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
                "\n",
                "### ìš”ì•½ (Summarization)\n",
                "\n",
                "í† í° ì œí•œì— ì ‘ê·¼í•  ë•Œ ëŒ€í™” ê¸°ë¡ì„ ìë™ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.\n",
                "\n",
                "**ì í•©í•œ ê²½ìš°:**\n",
                "- ì»¨í…ìŠ¤íŠ¸ ì°½ì„ ì´ˆê³¼í•˜ëŠ” ì¥ê¸° ì‹¤í–‰ ëŒ€í™”\n",
                "- ê´‘ë²”ìœ„í•œ ê¸°ë¡ì´ ìˆëŠ” ë‹¤ì¤‘ í„´ ëŒ€í™”\n",
                "- ì „ì²´ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ë³´ì¡´ì´ ì¤‘ìš”í•œ ì• í”Œë¦¬ì¼€ì´ì…˜"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.agents import create_agent\n",
                "from langchain.agents.middleware import SummarizationMiddleware\n",
                "\n",
                "agent = create_agent(\n",
                "    model=model,\n",
                "    tools=[get_weather],\n",
                "    middleware=[\n",
                "        SummarizationMiddleware(\n",
                "            model=\"openai:gpt-4.1-mini\",\n",
                "            max_tokens_before_summary=4000,  # 4000 í† í°ì—ì„œ ìš”ì•½ íŠ¸ë¦¬ê±°\n",
                "            messages_to_keep=20,  # ìš”ì•½ í›„ ìµœê·¼ 20ê°œ ë©”ì‹œì§€ ìœ ì§€\n",
                "        ),\n",
                "    ],\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ëª¨ë¸ í˜¸ì¶œ ì œí•œ (ModelCallLimitMiddleware)\n",
                "\n",
                "ë¬´í•œ ë£¨í”„ë‚˜ ê³¼ë„í•œ ë¹„ìš©ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ëª¨ë¸ í˜¸ì¶œ ìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤.\n",
                "\n",
                "**ì í•©í•œ ê²½ìš°:**\n",
                "- ì—ì´ì „íŠ¸ê°€ ë„ˆë¬´ ë§ì€ API í˜¸ì¶œì„ í•˜ëŠ” ê²ƒì„ ë°©ì§€\n",
                "- í”„ë¡œë•ì…˜ ë°°í¬ì— ëŒ€í•œ ë¹„ìš© ì œì–´ ì‹œí–‰\n",
                "- íŠ¹ì • í˜¸ì¶œ ì˜ˆì‚° ë‚´ì—ì„œ ì—ì´ì „íŠ¸ ë™ì‘ í…ŒìŠ¤íŠ¸"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.agents.middleware import ModelCallLimitMiddleware\n",
                "\n",
                "agent = create_agent(\n",
                "    model=model,\n",
                "    tools=[get_weather],\n",
                "    middleware=[\n",
                "        ModelCallLimitMiddleware(\n",
                "            thread_limit=3,  # ìŠ¤ë ˆë“œë‹¹ ìµœëŒ€ 10íšŒ í˜¸ì¶œ (ì‹¤í–‰ ì „ë°˜)\n",
                "            run_limit=2,  # ì‹¤í–‰ë‹¹ ìµœëŒ€ 5íšŒ í˜¸ì¶œ (ë‹¨ì¼ í˜¸ì¶œ)\n",
                "            exit_behavior=\"end\",  # ë˜ëŠ” \"error\"ë¡œ ì˜ˆì™¸ ë°œìƒ\n",
                "        ),\n",
                "    ],\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ë„êµ¬ í˜¸ì¶œ ì œí•œ (Tool Call Limit)\n",
                "\n",
                "íŠ¹ì • ë„êµ¬ ë˜ëŠ” ëª¨ë“  ë„êµ¬ì— ëŒ€í•œ í˜¸ì¶œ ìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤.\n",
                "\n",
                "**ì í•©í•œ ê²½ìš°:**\n",
                "- ë¹„ìš©ì´ ë§ì´ ë“œëŠ” ì™¸ë¶€ APIì— ëŒ€í•œ ê³¼ë„í•œ í˜¸ì¶œ ë°©ì§€\n",
                "- ì›¹ ê²€ìƒ‰ ë˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì œí•œ\n",
                "- íŠ¹ì • ë„êµ¬ ì‚¬ìš©ì— ëŒ€í•œ ì†ë„ ì œí•œ ì‹œí–‰"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.agents.middleware import ToolCallLimitMiddleware\n",
                "\n",
                "# ëª¨ë“  ë„êµ¬ í˜¸ì¶œ ì œí•œ\n",
                "global_limiter = ToolCallLimitMiddleware(thread_limit=20, run_limit=10)\n",
                "\n",
                "# íŠ¹ì • ë„êµ¬ ì œí•œ\n",
                "weather_limiter = ToolCallLimitMiddleware(\n",
                "    tool_name=\"get_weather\",\n",
                "    thread_limit=5,\n",
                "    run_limit=3,\n",
                ")\n",
                "\n",
                "agent = create_agent(\n",
                "    model=model,\n",
                "    tools=[get_weather],\n",
                "    middleware=[global_limiter, weather_limiter],\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ëª¨ë¸ í´ë°± (Model Fallback)\n",
                "\n",
                "ê¸°ë³¸ ëª¨ë¸ì´ ì‹¤íŒ¨í•  ë•Œ ëŒ€ì²´ ëª¨ë¸ë¡œ ìë™ í´ë°±í•©ë‹ˆë‹¤.\n",
                "\n",
                "**ì í•©í•œ ê²½ìš°:**\n",
                "- ëª¨ë¸ ì¤‘ë‹¨ì„ ì²˜ë¦¬í•˜ëŠ” ë³µì›ë ¥ ìˆëŠ” ì—ì´ì „íŠ¸ êµ¬ì¶•\n",
                "- ë” ì €ë ´í•œ ëª¨ë¸ë¡œ í´ë°±í•˜ì—¬ ë¹„ìš© ìµœì í™”\n",
                "- OpenAI, Anthropic ë“±ì— ê±¸ì¹œ ì œê³µì ì¤‘ë³µì„±"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.agents.middleware import ModelFallbackMiddleware\n",
                "\n",
                "agent = create_agent(\n",
                "    model=\"openai:gpt-4.1\",  # ê¸°ë³¸ ëª¨ë¸\n",
                "    tools=[get_weather],\n",
                "    middleware=[\n",
                "        ModelFallbackMiddleware(\n",
                "            \"openai:gpt-4.1-mini\",  # ì˜¤ë¥˜ ì‹œ ë¨¼ì € ì‹œë„\n",
                "            \"anthropic:claude-4-5-haiku\",  # ê·¸ ë‹¤ìŒ ì´ê²ƒ\n",
                "        ),\n",
                "    ],\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### PII ê°ì§€ (PII Detection)\n",
                "\n",
                "ëŒ€í™”ì—ì„œ ê°œì¸ ì‹ë³„ ì •ë³´ë¥¼ ê°ì§€í•˜ê³  ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
                "\n",
                "**ì í•©í•œ ê²½ìš°:**\n",
                "- ê·œì • ì¤€ìˆ˜ ìš”êµ¬ ì‚¬í•­ì´ ìˆëŠ” ì˜ë£Œ ë° ê¸ˆìœµ ì• í”Œë¦¬ì¼€ì´ì…˜\n",
                "- ë¡œê·¸ë¥¼ ì •í™”í•´ì•¼ í•˜ëŠ” ê³ ê° ì„œë¹„ìŠ¤ ì—ì´ì „íŠ¸\n",
                "- ë¯¼ê°í•œ ì‚¬ìš©ì ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ëª¨ë“  ì• í”Œë¦¬ì¼€ì´ì…˜"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "I noticed that you shared sensitive information such as your credit card number, API key, and email. For your privacy and security, please avoid sharing such information here.\n",
                        "\n",
                        "How can I assist you today? If you have any questions or need help with something specific, feel free to let me know!\n"
                    ]
                }
            ],
            "source": [
                "from langchain.agents.middleware import PIIMiddleware\n",
                "\n",
                "agent = create_agent(\n",
                "    model=model,\n",
                "    tools=[get_weather],\n",
                "    middleware=[\n",
                "        # ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì´ë©”ì¼ ìˆ˜ì •\n",
                "        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_input=True),\n",
                "        # ì‹ ìš©ì¹´ë“œ ë§ˆìŠ¤í‚¹ (ë§ˆì§€ë§‰ 4ìë¦¬ í‘œì‹œ)\n",
                "        PIIMiddleware(\"credit_card\", strategy=\"mask\", apply_to_input=True),\n",
                "        # ì •ê·œì‹ì„ ì‚¬ìš©í•œ ì»¤ìŠ¤í…€ PII ìœ í˜•\n",
                "        PIIMiddleware(\n",
                "            \"api_key\",\n",
                "            detector=r\"sk-[a-zA-Z0-9]{32}\",\n",
                "            strategy=\"mask\",  # ê°ì§€ ì‹œ ì˜¤ë¥˜ ë°œìƒ\n",
                "        ),\n",
                "    ],\n",
                ")\n",
                "\n",
                "# PII ê°ì§€ í…ŒìŠ¤íŠ¸\n",
                "result = agent.invoke(\n",
                "    {\n",
                "        \"messages\": [\n",
                "            {\n",
                "                \"role\": \"user\",\n",
                "                \"content\": \"My credit card number is 1234-5678-9012-3456, and my API key is sk-12345678901234567890123456789012, My email is teddy@example.com. Can you help me?\",\n",
                "            }\n",
                "        ]\n",
                "    }\n",
                ")\n",
                "print(result[\"messages\"][-1].content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ë„êµ¬ ì¬ì‹œë„ (Tool Retry)\n",
                "\n",
                "êµ¬ì„± ê°€ëŠ¥í•œ ì§€ìˆ˜ ë°±ì˜¤í”„ë¡œ ì‹¤íŒ¨í•œ ë„êµ¬ í˜¸ì¶œì„ ìë™ìœ¼ë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤.\n",
                "\n",
                "**ì í•©í•œ ê²½ìš°:**\n",
                "- ì™¸ë¶€ API í˜¸ì¶œì˜ ì¼ì‹œì ì¸ ì‹¤íŒ¨ ì²˜ë¦¬\n",
                "- ë„¤íŠ¸ì›Œí¬ ì¢…ì† ë„êµ¬ì˜ ì•ˆì •ì„± í–¥ìƒ\n",
                "- ì¼ì‹œì ì¸ ì˜¤ë¥˜ë¥¼ ìš°ì•„í•˜ê²Œ ì²˜ë¦¬í•˜ëŠ” ë³µì›ë ¥ ìˆëŠ” ì—ì´ì „íŠ¸ êµ¬ì¶•"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.agents.middleware import ToolRetryMiddleware\n",
                "\n",
                "agent = create_agent(\n",
                "    model=model,\n",
                "    tools=[get_weather],\n",
                "    middleware=[\n",
                "        ToolRetryMiddleware(\n",
                "            max_retries=3,  # ìµœëŒ€ 3íšŒ ì¬ì‹œë„\n",
                "            backoff_factor=2.0,  # ì§€ìˆ˜ ë°±ì˜¤í”„ ìŠ¹ìˆ˜\n",
                "            initial_delay=1.0,  # 1ì´ˆ ì§€ì—°ìœ¼ë¡œ ì‹œì‘\n",
                "            max_delay=60.0,  # ì§€ì—°ì„ 60ì´ˆë¡œ ì œí•œ\n",
                "            jitter=True,  # ë¬´ì‘ìœ„ ì§€í„° ì¶”ê°€\n",
                "        ),\n",
                "    ],\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ì»¤ìŠ¤í…€ ë¯¸ë“¤ì›¨ì–´(ì¶”ì²œ)\n",
                "\n",
                "ì—ì´ì „íŠ¸ ì‹¤í–‰ íë¦„ì˜ íŠ¹ì • ì§€ì ì—ì„œ ì‹¤í–‰ë˜ëŠ” í›„í¬ë¥¼ êµ¬í˜„í•˜ì—¬ ì»¤ìŠ¤í…€ ë¯¸ë“¤ì›¨ì–´ë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
                "\n",
                "ë¯¸ë“¤ì›¨ì–´ë¥¼ ë§Œë“œëŠ” ë‘ ê°€ì§€ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤:\n",
                "\n",
                "1. **ë°ì½”ë ˆì´í„° ê¸°ë°˜** - ë‹¨ì¼ í›„í¬ ë¯¸ë“¤ì›¨ì–´ì— ë¹ ë¥´ê³  ê°„ë‹¨\n",
                "2. **í´ë˜ìŠ¤ ê¸°ë°˜** - ì—¬ëŸ¬ í›„í¬ê°€ ìˆëŠ” ë³µì¡í•œ ë¯¸ë“¤ì›¨ì–´ì— ë” ê°•ë ¥"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ë°ì½”ë ˆì´í„° ê¸°ë°˜ ë¯¸ë“¤ì›¨ì–´\n",
                "\n",
                "ë‹¨ì¼ í›„í¬ë§Œ í•„ìš”í•œ ê°„ë‹¨í•œ ë¯¸ë“¤ì›¨ì–´ì˜ ê²½ìš° ë°ì½”ë ˆì´í„°ê°€ ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ëŠ” ê°€ì¥ ë¹ ë¥¸ ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ì—ì´ì „íŠ¸ë¥¼ ì‹œì‘í•˜ê¸° ì „ì— ë©”ì‹œì§€ 1ê°œê°€ ìˆìŠµë‹ˆë‹¤\n",
                        "\n",
                        "==================================================\n",
                        "ğŸ”„ Node: \u001b[1;36mlog_before_agent.before_agent\u001b[0m ğŸ”„\n",
                        "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
                        "==================================================\n",
                        "ëª¨ë¸ì„ í˜¸ì¶œí•˜ê¸° ì „ì— ë©”ì‹œì§€ 1ê°œê°€ ìˆìŠµë‹ˆë‹¤\n",
                        "\n",
                        "==================================================\n",
                        "ğŸ”„ Node: \u001b[1;36mlog_before_model.before_model\u001b[0m ğŸ”„\n",
                        "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
                        "==================================================\n",
                        "\n",
                        "==================================================\n",
                        "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
                        "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
                        "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
                        "Tool Calls:\n",
                        "  get_weather (call_h6T2O94uSVMIzI18OfWWGoZf)\n",
                        " Call ID: call_h6T2O94uSVMIzI18OfWWGoZf\n",
                        "  Args:\n",
                        "    city: ì„œìš¸\n",
                        "==================================================\n",
                        "\n",
                        "==================================================\n",
                        "ğŸ”„ Node: \u001b[1;36mvalidate_output.after_model\u001b[0m ğŸ”„\n",
                        "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
                        "==================================================\n",
                        "\n",
                        "==================================================\n",
                        "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m ğŸ”„\n",
                        "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
                        "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
                        "Name: get_weather\n",
                        "\n",
                        "It's sunny in ì„œìš¸!\n",
                        "==================================================\n",
                        "ëª¨ë¸ì„ í˜¸ì¶œí•˜ê¸° ì „ì— ë©”ì‹œì§€ 3ê°œê°€ ìˆìŠµë‹ˆë‹¤\n",
                        "\n",
                        "==================================================\n",
                        "ğŸ”„ Node: \u001b[1;36mlog_before_model.before_model\u001b[0m ğŸ”„\n",
                        "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
                        "==================================================\n",
                        "\n",
                        "==================================================\n",
                        "ğŸ”„ Node: \u001b[1;36mmodel\u001b[0m ğŸ”„\n",
                        "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
                        "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
                        "\n",
                        "ì•ˆë…•í•˜ì„¸ìš” Teddy! ì„œìš¸ì€ ì§€ê¸ˆ ë§‘ì€ ë‚ ì”¨ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
                        "==================================================\n",
                        "\n",
                        "==================================================\n",
                        "ğŸ”„ Node: \u001b[1;36mvalidate_output.after_model\u001b[0m ğŸ”„\n",
                        "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
                        "==================================================\n",
                        "ì—ì´ì „íŠ¸ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ë©”ì‹œì§€ ìˆ˜: 4ê°œ\n",
                        "\n",
                        "==================================================\n",
                        "ğŸ”„ Node: \u001b[1;36mlog_after_agent.after_agent\u001b[0m ğŸ”„\n",
                        "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
                        "==================================================\n"
                    ]
                }
            ],
            "source": [
                "from langchain.agents.middleware import (\n",
                "    before_agent,\n",
                "    before_model,\n",
                "    after_model,\n",
                "    after_agent,\n",
                "    wrap_model_call,\n",
                "    wrap_tool_call,\n",
                ")\n",
                "from langchain.agents.middleware import (\n",
                "    AgentState,\n",
                "    ModelRequest,\n",
                "    ModelResponse,\n",
                "    dynamic_prompt,\n",
                ")\n",
                "from langchain.messages import AIMessage\n",
                "from langchain_teddynote.messages import invoke_graph\n",
                "from langgraph.runtime import Runtime\n",
                "from typing import Any, Callable\n",
                "\n",
                "\n",
                "# ë…¸ë“œ ìŠ¤íƒ€ì¼: ëª¨ë¸ í˜¸ì¶œ ì „ ë¡œê¹…\n",
                "@before_model\n",
                "def log_before_model(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
                "    print(f\"ëª¨ë¸ì„ í˜¸ì¶œí•˜ê¸° ì „ì— ë©”ì‹œì§€ {len(state['messages'])}ê°œê°€ ìˆìŠµë‹ˆë‹¤\")\n",
                "    return None\n",
                "\n",
                "\n",
                "# ë…¸ë“œ ìŠ¤íƒ€ì¼: ëª¨ë¸ í˜¸ì¶œ í›„ ê²€ì¦\n",
                "@after_model\n",
                "def validate_output(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
                "    last_message = state[\"messages\"][-1]\n",
                "    if \"BLOCKED\" in last_message.content:\n",
                "        return {\n",
                "            \"messages\": [AIMessage(\"I cannot respond to that request.\")],\n",
                "        }\n",
                "    return None\n",
                "\n",
                "\n",
                "@before_agent\n",
                "def log_before_agent(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
                "    print(f\"ì—ì´ì „íŠ¸ë¥¼ ì‹œì‘í•˜ê¸° ì „ì— ë©”ì‹œì§€ {len(state['messages'])}ê°œê°€ ìˆìŠµë‹ˆë‹¤\")\n",
                "    return None\n",
                "\n",
                "\n",
                "@after_agent\n",
                "def log_after_agent(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
                "    print(f\"ì—ì´ì „íŠ¸ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ë©”ì‹œì§€ ìˆ˜: {len(state['messages'])}ê°œ\")\n",
                "\n",
                "    return None\n",
                "\n",
                "\n",
                "# wrap_model_call ì¬ì‹œë„ ë¡œì§\n",
                "@wrap_model_call\n",
                "def retry_model(\n",
                "    request: ModelRequest,\n",
                "    handler: Callable[[ModelRequest], ModelResponse],\n",
                ") -> ModelResponse:\n",
                "    for attempt in range(3):\n",
                "        try:\n",
                "            return handler(request)\n",
                "        except Exception as e:\n",
                "            if attempt == 2:\n",
                "                raise\n",
                "            print(f\"ì˜¤ë¥˜ ë°œìƒìœ¼ë¡œ {attempt + 1}/3 ë²ˆì§¸ ì¬ì‹œë„í•©ë‹ˆë‹¤: {e}\")\n",
                "\n",
                "\n",
                "# ë™ì  í”„ë¡¬í”„íŠ¸\n",
                "@dynamic_prompt\n",
                "def personalized_prompt(request: ModelRequest) -> str:\n",
                "    user_id = request.runtime.context.get(\"user_id\", \"guest\")\n",
                "    return f\"You are a helpful assistant for user {user_id}. Greeting with user's name. Be concise and friendly.\"\n",
                "\n",
                "\n",
                "# ì—ì´ì „íŠ¸ì—ì„œ ë°ì½”ë ˆì´í„° ì‚¬ìš©\n",
                "agent = create_agent(\n",
                "    model=model,\n",
                "    middleware=[\n",
                "        log_before_model,\n",
                "        validate_output,\n",
                "        retry_model,\n",
                "        personalized_prompt,\n",
                "        log_before_agent,\n",
                "        log_after_agent,\n",
                "    ],\n",
                "    tools=[get_weather],\n",
                ")\n",
                "\n",
                "invoke_graph(\n",
                "    agent,\n",
                "    inputs={\"messages\": [{\"role\": \"user\", \"content\": \"ì„œìš¸ ë‚ ì”¨ ì•Œë ¤ì¤˜\"}]},\n",
                "    context={\"user_id\": \"teddy\"},\n",
                "    config=RunnableConfig(),\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### í´ë˜ìŠ¤ ê¸°ë°˜ ë¯¸ë“¤ì›¨ì–´\n",
                "\n",
                "ë³µì¡í•œ ë¯¸ë“¤ì›¨ì–´ì˜ ê²½ìš° í´ë˜ìŠ¤ ê¸°ë°˜ ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ í›„í¬ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
                "\n",
                "#### ë…¸ë“œ ìŠ¤íƒ€ì¼ í›„í¬\n",
                "\n",
                "ì‹¤í–‰ íë¦„ì˜ íŠ¹ì • ì§€ì ì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤:\n",
                "- `before_agent` - ì—ì´ì „íŠ¸ ì‹œì‘ ì „ (í˜¸ì¶œë‹¹ í•œ ë²ˆ)\n",
                "- `before_model` - ê° ëª¨ë¸ í˜¸ì¶œ ì „\n",
                "- `after_model` - ê° ëª¨ë¸ ì‘ë‹µ í›„\n",
                "- `after_agent` - ì—ì´ì „íŠ¸ ì™„ë£Œ í›„ (í˜¸ì¶œë‹¹ ìµœëŒ€ í•œ ë²ˆ)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.agents.middleware import AgentMiddleware, AgentState\n",
                "from langgraph.runtime import Runtime\n",
                "from typing import Any\n",
                "\n",
                "\n",
                "# ë¡œê¹… ë¯¸ë“¤ì›¨ì–´\n",
                "class LoggingMiddleware(AgentMiddleware):\n",
                "    def before_model(\n",
                "        self, state: AgentState, runtime: Runtime\n",
                "    ) -> dict[str, Any] | None:\n",
                "        print(f\"About to call model with {len(state['messages'])} messages\")\n",
                "        return None\n",
                "\n",
                "    def after_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
                "        print(f\"Model returned: {state['messages'][-1].content[:50]}...\")\n",
                "        return None\n",
                "\n",
                "\n",
                "agent = create_agent(\n",
                "    model=model,\n",
                "    tools=[get_weather],\n",
                "    middleware=[LoggingMiddleware()],\n",
                ")\n",
                "\n",
                "result = agent.invoke(\n",
                "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's the weather in Tokyo?\"}]}\n",
                ")\n",
                "print(\"\\nFinal:\", result[\"messages\"][-1].content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### ëŒ€í™” ê¸¸ì´ ì œí•œ ì˜ˆì œ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.agents.middleware import AgentMiddleware, AgentState\n",
                "from langchain.messages import AIMessage\n",
                "from langgraph.runtime import Runtime\n",
                "from typing import Any\n",
                "\n",
                "\n",
                "class MessageLimitMiddleware(AgentMiddleware):\n",
                "    def __init__(self, max_messages: int = 50):\n",
                "        super().__init__()\n",
                "        self.max_messages = max_messages\n",
                "\n",
                "    def before_model(\n",
                "        self, state: AgentState, runtime: Runtime\n",
                "    ) -> dict[str, Any] | None:\n",
                "        if len(state[\"messages\"]) >= self.max_messages:\n",
                "            return {\n",
                "                \"messages\": [AIMessage(\"Conversation limit reached.\")],\n",
                "            }\n",
                "        return None\n",
                "\n",
                "\n",
                "agent = create_agent(\n",
                "    model=model,\n",
                "    tools=[get_weather],\n",
                "    middleware=[MessageLimitMiddleware(max_messages=10)],\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### ë© ìŠ¤íƒ€ì¼ í›„í¬\n",
                "\n",
                "ì‹¤í–‰ì„ ê°€ë¡œì±„ê³  í•¸ë“¤ëŸ¬ê°€ í˜¸ì¶œë˜ëŠ” ì‹œê¸°ë¥¼ ì œì–´í•©ë‹ˆë‹¤:\n",
                "- `wrap_model_call` - ê° ëª¨ë¸ í˜¸ì¶œ ì£¼ë³€\n",
                "- `wrap_tool_call` - ê° ë„êµ¬ í˜¸ì¶œ ì£¼ë³€\n",
                "\n",
                "í•¸ë“¤ëŸ¬ë¥¼ 0ë²ˆ(ë‹¨ë½), 1ë²ˆ(ì •ìƒ íë¦„) ë˜ëŠ” ì—¬ëŸ¬ ë²ˆ(ì¬ì‹œë„ ë¡œì§) í˜¸ì¶œí• ì§€ ê²°ì •í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.agents.middleware import AgentMiddleware, ModelRequest, ModelResponse\n",
                "from typing import Callable\n",
                "\n",
                "\n",
                "class RetryMiddleware(AgentMiddleware):\n",
                "    def __init__(self, max_retries: int = 3):\n",
                "        super().__init__()\n",
                "        self.max_retries = max_retries\n",
                "\n",
                "    def wrap_model_call(\n",
                "        self,\n",
                "        request: ModelRequest,\n",
                "        handler: Callable[[ModelRequest], ModelResponse],\n",
                "    ) -> ModelResponse:\n",
                "        for attempt in range(self.max_retries):\n",
                "            try:\n",
                "                return handler(request)\n",
                "            except Exception as e:\n",
                "                if attempt == self.max_retries - 1:\n",
                "                    raise\n",
                "                print(f\"Retry {attempt + 1}/{self.max_retries} after error: {e}\")\n",
                "\n",
                "\n",
                "agent = create_agent(\n",
                "    model=model,\n",
                "    tools=[get_weather],\n",
                "    middleware=[RetryMiddleware(max_retries=3)],\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### ë™ì  ëª¨ë¸ ì„ íƒ ì˜ˆì œ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.agents.middleware import AgentMiddleware, ModelRequest, ModelResponse\n",
                "from langchain.chat_models import init_chat_model\n",
                "from typing import Callable\n",
                "\n",
                "\n",
                "class DynamicModelMiddleware(AgentMiddleware):\n",
                "    def wrap_model_call(\n",
                "        self,\n",
                "        request: ModelRequest,\n",
                "        handler: Callable[[ModelRequest], ModelResponse],\n",
                "    ) -> ModelResponse:\n",
                "        # ëŒ€í™” ê¸¸ì´ì— ë”°ë¼ ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš©\n",
                "        if len(request.messages) > 10:\n",
                "            request.model = init_chat_model(\"openai:gpt-4.1\")\n",
                "            print(\"Using gpt-4.1 for long conversation\")\n",
                "        else:\n",
                "            request.model = init_chat_model(\"openai:gpt-4.1-mini\")\n",
                "            print(\"Using gpt-4.1-mini for short conversation\")\n",
                "\n",
                "        return handler(request)\n",
                "\n",
                "\n",
                "agent = create_agent(\n",
                "    model=model,\n",
                "    tools=[get_weather],\n",
                "    middleware=[DynamicModelMiddleware()],\n",
                ")\n",
                "\n",
                "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]})\n",
                "print(result[\"messages\"][-1].content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ì‹¤í–‰ ìˆœì„œ\n",
                "\n",
                "ì—¬ëŸ¬ ë¯¸ë“¤ì›¨ì–´ë¥¼ ì‚¬ìš©í•  ë•Œ ì‹¤í–‰ ìˆœì„œë¥¼ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
                "\n",
                "**ì£¼ìš” ê·œì¹™:**\n",
                "- `before_*` í›„í¬: ì²« ë²ˆì§¸ë¶€í„° ë§ˆì§€ë§‰ê¹Œì§€\n",
                "- `after_*` í›„í¬: ë§ˆì§€ë§‰ë¶€í„° ì²« ë²ˆì§¸ê¹Œì§€ (ì—­ìˆœ)\n",
                "- `wrap_*` í›„í¬: ì¤‘ì²©ë¨ (ì²« ë²ˆì§¸ ë¯¸ë“¤ì›¨ì–´ê°€ ë‹¤ë¥¸ ëª¨ë“  ê²ƒì„ ë˜í•‘)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.agents.middleware import AgentMiddleware\n",
                "\n",
                "\n",
                "class Middleware1(AgentMiddleware):\n",
                "    def before_model(self, state, runtime):\n",
                "        print(\"1: before_model\")\n",
                "        return None\n",
                "\n",
                "    def after_model(self, state, runtime):\n",
                "        print(\"1: after_model\")\n",
                "        return None\n",
                "\n",
                "\n",
                "class Middleware2(AgentMiddleware):\n",
                "    def before_model(self, state, runtime):\n",
                "        print(\"2: before_model\")\n",
                "        return None\n",
                "\n",
                "    def after_model(self, state, runtime):\n",
                "        print(\"2: after_model\")\n",
                "        return None\n",
                "\n",
                "\n",
                "# ì‹¤í–‰ ìˆœì„œ í™•ì¸\n",
                "agent = create_agent(\n",
                "    model=model,\n",
                "    tools=[get_weather],\n",
                "    middleware=[Middleware1(), Middleware2()],\n",
                ")\n",
                "\n",
                "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]})\n",
                "\n",
                "# ì¶œë ¥:\n",
                "# 1: before_model\n",
                "# 2: before_model\n",
                "# (ëª¨ë¸ í˜¸ì¶œ)\n",
                "# 2: after_model\n",
                "# 1: after_model"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
